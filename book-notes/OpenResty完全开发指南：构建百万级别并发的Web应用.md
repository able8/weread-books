## OpenResty完全开发指南：构建百万级别并发的Web应用
> 罗剑锋

### 作者介绍

主要研究方向为C/C++、设计模式、高性能网络服务器开发

业余爱好是阅读、旅游、欣赏音乐和电影

### 内容简介

OpenResty是一个基于Nginx的高性能Web平台，能够方便地搭建处理超高并发的动态Web应用、Web服务和动态网关。

系统地阐述了OpenResty相关的各方面知识和要点，帮助读者快速掌握这个高效易用的Web开发平台，进而实现HTTP/HTTPS/TCP/UDP等多种网络应用。

### 前言

Nginx在Web Server业内的领军地位早已经得到了公认，是高性能服务器的杰出代表。它采用C语言开发，能够跨平台运行，把性能挖掘优化技术发挥到了极致。

基于Nginx开发主要使用的语言是C/C++，开发难度高周期长，虽然没有达到“望而生畏”的程度但亦不远矣。好在OpenResty应运而生，在Nginx里嵌入了LuaJIT环境和Lua语言，就如同给裸系统添加了一个高效易用的Shell，瞬间就让Nginx开发的难度直线下降，降低到了普通的心智模型可以理解掌握的水平。

早期OpenResty对于自身的定位主要还是HTTP Server（其实也是受到Nginx的限制），可以利用“胶水语言”Lua来操纵Nginx，灵活定制业务逻辑，方便快捷地搭建出超高并发的各种Web服务，从而节约时间和人力成本。多年来的实践证明，这方面它的确工作得非常出色。

### 第0章 导读

OpenResty是一个基于Nginx的高性能Web平台，能够方便地使用动态脚本语言Lua搭建高并发、高扩展性的Web应用和动态网关。

### 0.2 读者对象

■ 微服务、API网关、Web应用防火墙的研发工程师；

现在的网站架构大都是分布式系统，经常部署有成百上千个内部模块，这些模块通常基于“微服务”“服务网格”等架构，彼此之间的联系十分复杂，在演化过程中系统会逐渐变得难以理解和维护。OpenResty具有优秀的反向代理和负载均衡能力，在复杂的分布式系统中可以充当API Gateway的角色，分治整合不同种类的服务简化系统，并使用内嵌的Lua脚本添加缓冲、限流、防护、认证等额外功能。

### 第1章 总论

开源项目OpenResty成功地把Lua语言嵌入了Nginx，用Lua作为“胶水语言”粘合Nginx的各个模块和底层接口，以脚本的方式直接实现复杂的HTTP/TCP/UDP业务逻辑，降低了Web Server——特别是高性能Web Server的开发门槛。

很多国内外大型网站都在使用OpenResty开发后端应用，而且越来越多，知名的国外公司有Adobe、CloudFlare、Dropbox、GitHub等，国内则有12306、阿里、爱奇艺、京东、美团、奇虎、新浪等，充分地证明了OpenResty的优秀

### 1.1 简介

OpenResty基于Nginx和Lua/LuaJIT，充分利用了两者的优势，能够无阻塞地处理海量并发连接，任意操纵HTTP/TCP/UDP数据流，而且功能代码不需要编译，可以就地修改脚本并运行，简化了开发流程，加快了开发和调试的速度，同时也缩短了开发周期，在如今这个快节奏的时代里弥足珍贵。

### 1.2 历史

2007年，受到当时风行的OpenAPI和REST潮流的影响，agentzh使用Perl语言（还有少量的Haskell）开发出了一套Web Service框架，也就是如今OpenResty的雏形。由于Perl语言自身的限制，虽然agentzh做了很多优化工作，但性能始终无法令人满意

2011年，随着OpenResty的用户逐渐增多，开源项目与本职工作的冲突越来越严重，agentzh于是辞职在家，专心维护OpenResty，为全世界的程序员提供“免费服务”。

### 1.11 性能对比

的数据可见OpenResty的运行效率是最高的，在RPS指标上是Node.js的3.1倍，Go的1.6倍，PHP的2.5倍，远远胜出。

对于高负荷的网站来说，即使是5%!~(MISSING)10%!的(MISSING)性能提升都是非常有价值的，更何况是50%!~(MISSING)200%!。(MISSING)注意这还是未经优化的结果，实际上OpenResty还可以轻松开启多个进程服务，成倍地扩充服务能力。

### 1.12 应用架构

OpenResty也可以充当APIGateway，以RESTful接口为基础聚合整理各种后端服务，并增加监控、缓存、权限控制等功能，改善系统的运行效率。

### 第2章 Nginx平台

Nginx[插图]的首个公开版发布于2004年，

### 2.1 简介

Nginx是一个高性能、高稳定的轻量级HTTP、TCP、UDP和反向代理服务器。它运行效率高，资源消耗低，不需要很高的硬件配置就可以轻松地处理上万的并发请求，是当今Web服务器中的佼佼者，被国内外许多知名网站所采用。

Nginx最突出的特点是卓越的性能。它采用事件驱动，不使用传统的进程或线程服务器模型，没有进程或线程切换时的成本，并且有针对性地对操作系统进行了特别优化，能够无阻塞地处理10K乃至100K的海量连接。

### 2.2 进程模型

Nginx会启动一个master进程和多个worker进程。master进程又称监控进程，它并不处理具体的TCP/HTTP请求，只负责管理和监控worker进程。多个worker进程从属于master进程，构成一个“池”，真正对外提供Web服务，执行主要的业务逻辑，可以充分利用多核CPU高效率地处理HTTP/TCP请求。

其中进程号为16985的是master进程，而16986号进程则是worker进程。

### 2.3 配置文件

■ 配置指令以分号结束，可以接受多个参数，用空白字符分隔；■ 配置块（block）是特殊的配置指令，它有一个{}参数且无须分号结束，{}里面可以书写多个配置指令，配置块也允许嵌套；

### 2.5 HTTP服务

location指令定义Web服务的接口（相当于RESTful里的API），也就是URI，它是OpenResty处理的入口，决定了请求应该如何处理。

### 2.6 TCP/UDP服务

配置TCP/UDP相关的功能需要使用指令stream{}，形式与http块非常类似

### 2.7 反向代理

反向代理（Reverse Proxy）是现今网络中一种非常重要的技术，它位于客户端和真正的服务器（即所谓的后端）之间，接受客户端的请求并转发给后端，然后把后端的处理结果返回给客户端。从客户端的角度来看，访问反向代理和真正的后端服务器两者没有任何区别。

由于反向代理在客户端和服务器之间加入了中间层，可以执行复杂的逻辑，所以它有很多的用途，

[插图]

Nginx提供了优秀的反向代理功能，不仅支持HTTP反向代理，也支持TCP/UDP反向代理，非常适合用在网络的核心位置担当“中流砥柱”的重任。

upstream块定义了在反向代理时需要访问的后端服务器集群和负载均衡策略（在Nginx里术语“upstream”代替了“backend”），可以在http{}或stream{}里配置。

在使用upstream配置了上游集群后，我们需要在location（http）或server stream）里用“proxy_pass”等指令把客户端的请求转发到后端，由Nginx根据负载均衡算法选择一台恰当的服务器提供服务，例如：

### 2.8 运行日志

日志是Web服务器非常重要的数字资产，它记录了服务器运行期间的各种信息，可用于数据分析或者排查故障。

Nginx的运行日志分为两种：记录HTTP/TCP访问请求的access_log和记录服务器各种错误信息的error_log。

访问日志保存了所有连接到服务器的客户端访问记录，在访问日志里可以记录每次请求的IP地址、URI、连接时间、收发字节数等许多信息。大多数网站会定期收集访问日志，然后使用大数据平台进行加工处理，进而调整优化服务。

### 3.1 简介

Lua语言最初的设计目标是要能够嵌入到其他应用程序里，所以它天生就非常“轻量级”，语法简洁优雅，很容易学习，任何一个有初级编程经验的人都可以在几天之内完全掌握并投入实际开发工作。

Lua语言小巧紧凑，本身只有一个精简的核心和最基本的库，所以代码的执行效率非常高，是所有脚本语言中速度最快的，这也使得它易于被移植或嵌入到各种软硬件平台，实现脚本化的扩展和定制功能，实用性很强。OpenResty选中它正是看中了这个特性。

### 3.11 面向对象

封装”方面，Lua不提供private、public这样的修饰词，表里的所有成员都是公开的。如果想要实现私有成员，那么可以在模块文件里用local修饰，这样local化的变量就对外界不可见了，而成员函数仍然可以访问

### 4.9 总结

Lua语言本身的运行效率就很高，而OpenResty为了追求性能的极致，使用的是更高效的LuaJIT。它利用了汇编语言和即时编译技术，可以把Lua源码程序即时编译成本地机器码，成倍地提升运行速度。

### 6.7 总结

OpenResty通过ngx_lua模块为我们提供了大量的功能接口，本章讲解了其中最基础的一些功能，除了ngx.sleep都可以在任意的执行阶段调用。ngx.config可以获取环境相关信息，如版本号、工作目录、子系统等，通常用于检测OpenResty运行环境，做简单的分支判断。ngx.log可以记录运行日志，它的用法类似标准库函数print，但多了个日志级别参数。在实际开发中应当利用ngx.log勤记日志，方便Debug排查错误。

### 7.1 简介

OpenResty基于Nginx提供了非常完善的HTTP处理功能，可以任意操作请求行、请求头、请求体、响应头、响应体，也支持chunked、keepalive、lingering_close等特性。

### 7.8 请求体

出于效率考虑，OpenResty不会主动读取客户端发送的请求体数据（除非使用7.2节的指令“lua_need_request_body on”），读取请求体需要执行下面的步骤：1) 调用函数ngx.req.read_body，开始读取请求体数据；2) 调用函数ngx.req.get_body_data获取数据，相当于$request_body；3) 如果得到是nil，可能是数据过大，存放在了磁盘文件里，调用函数ngx.req.get_body_file可以获得相应的临时文件名（相当于$request_body_file）；4) 使用io.*函数打开文件，读取数据（注意是阻塞操作！）。

### 第9章 反向代理

反向代理是OpenResty的一个重要用途，它资源消耗很低，转发性能极高，支持HTTP、FastCGI、Memcached、Redis、MySQL、gRPC等多种后端，所以经常用在网络的关键节点或网站架构的最前端，承担流量入口的重任，提高系统的整体可靠性。

作为反向代理，OpenResty除了最基本的数据转发功能，还具有负载均衡、内容缓冲、安全防护等许多高级特性，内嵌Lua脚本使它定制化程度更高，比起其他同类软件有更多的灵活性和竞争力。

### 9.1 简介

upstream系列指令定义了能够访问的后端服务器集群和负载均衡策略，是反向代理的核心。在OpenResty里可以使用upstream定义任意多个上游集群，分组管理众多的后端服务器。每个集群内部又可以再做分组，分为主服务器（primary）和备份服务器（backup）。主服务器提供正常的服务，备份服务器提供“应急”服务，当所有的主服务器都失效时才会启用备份服务器。集群里的服务器也可以拥有多个IP地址（通常是由于域名解析的原因），这在OpenResty里被称为“peer”，负载均衡算法基于peer而不是server进行调度。

代理转发指令实现向各种后端服务的请求转发，例如proxy_pass转发HTTP/HTTPS请求，fastcgi_pass转发FastCGI请求。它们利用upstream定义的集群和算法选择一个恰当的后端服务器，在客户端与后端服务器之间建立了一个高效的数据传输通道，并且还可以执行缓冲、过滤等附加功能，减轻后端的压力。

### 9.3 负载均衡

使用OpenResty做反向代理的传统模式是在配置文件的upstream{}块里书写多个服务器定义集群。这种方式不够灵活，增减服务器必须手动修改配置后重启OpenResty，会影响正常服务。OpenResty的“balancer_by_lua”指令让动态负载均衡成为了可能，它代替了原生的hash/ip_hash/least_conn等算法，不仅可以自由定制负载均衡策略，还可以随意调整后端服务器的数量，完全超越了upstream系列指令，实现接近商业版Nginx Plus的功能。

“balancer_by_lua”不涉及具体的请求处理，工作在upstream{}块内，需要预先定义一个“占位”用的server，而且之后不能定义其他的负载均衡算法（会导致冲突），如果还要使用keepalive指令则必须在它之后，例如

“balancer_by_lua”也是一个比较特殊的执行阶段，在这里不能使用ngx.sleep、ngx.req.*或cosocket，同时应当尽量避免大计算量操作或磁盘读写，否则会导致阻塞。

### 10.1 共享内存

OpenResty内置了强大的共享内存功能，不仅支持简单的数据存取，还支持原子计数和队列操作，用起来就像是一个微型的Redis数据库，极大地便利了worker进程间的通信和协作，而且还能够演化出许多新的用途，例如缓存、进程锁、流量统计等。[插图]

### 10.3 进程管理

OpenResty的进程模型基于Nginx，通常以master/worker多进程方式提供服务，各个worker进程互相平等且独立，由master进程通过信号管理各个worker进程。

### 10.4 轻量级线程

为了解决这个问题，OpenResty基于Lua的协程提出了“轻量级线程”（light thread）的概念，它非常类似于操作系统级别的线程，可以并发多个同时运行，但由OpenResty而不是系统内核来调度，所以很“轻量级”。

### 第11章 HTTPS服务

HTTP协议是明文传输，在如今的网络世界中显得越来越不安全，容易被监听、篡改或劫持，有很大的安全隐患。HTTPS在HTTP的基础上引入了SSL/TLS协议，成功解决了身份认证和数据加密两大关键问题，得到了越来越广泛的认可和应用，目前绝大多数主流网站都已经从HTTP协议转换到了HTTPS协议，在不远的将来Web服务必将都是HTTPS服务。

### 11.3 应用开发

由于HTTPS是“HTTP + SSL/TLS”，除了在建立连接的握手阶段外，整个请求的加密解密过程对于OpenResty来说是完全透明的

### 11.7 会话复用

HTTPS为网络通信带来了高度的安全，但这并不是“免费的午餐”，代价就是必须要花费更多的算力和时间用来加解密和验证。

整个HTTPS通信过程可以分为握手阶段和通信阶段。通信阶段使用的是对称加密，速度快，成本增加得不多；而握手阶段需要使用非对称算法多次加密解密，还需要反复交换数据协商密钥、证书，成本极高。所以就出现了很多种策略来优化握手过程，力图减少计算量和传输数据量，提高访问速度，其中会话复用（Session Resumption）是较有效的一种手段。

会话复用的原理很简单，因为第一次握手时已经互相认证了身份，算出了通信使用的密钥，那么只要把这个密钥存起来，下次通信时直接使用即可。显然，因为无须再做烦琐的协商验证，这部分的计算和网络开销就节省下来了

### 第12章 HTTP2服务

HTTP2协议脱胎于SPDY协议，是HTTP 1.0/1.1的升级和优化，相比于HTTPS协议，它的目标是解决网络性能问题。[插图]自2015年正式公布后，经过三年多的时间，HTTP2已经获得了各大浏览器（Firefox、Chrome、Safari等）和服务器（Apache、Nginx等）的全力支持，而且还扩展到了其他的应用领域，例如服务开发框架gRPC，呈现出加速发展的趋势。

### 12.1 简介

HTTP1.0协议诞生于1996年，之后的1.1版本又对它做了很多的扩展和完善。时至今日，HTTP协议已经成为了整个互联网世界应用的最广泛的协议，无数的应用服务构建于它之上，为互联网的普及和发展做出了卓越的贡献。

HTTP1.x也逐渐暴露出了当初设计时的许多不足之处，特别是性能上越来越难以应对日益增长的网络需求。虽然在多年的使用过程中也“发明”了各式各样的小技巧（如切图、内嵌数据、JS合并等），但都是“治标不治本”，最根本的HTTP协议没有任何改动，导致性能改善并不明显。

2010年，Google推出了SPDY协议，在多个方面增强了（而不是替代）HTTP协议，力图在不打破现状的情况下提升数据传输效率和安全性。由于SPDY协议性能表现极佳，而且获得了众多业内的支持，互联网标准组织IETF决定以SPDY协议为基础制订HTTP2协议，最终于2015年正式发布（RFC 7540）。

为了保护互联网上的大量既存服务，HTTP2首先强调的就是对HTTP1.x的高度兼容，基本的请求/应答模式、请求方法、URI、头部信息等都没有任何改变，尤其值得一提的是，并没有“http2://...”这样的协议名字，HTTP2的目标是用户可以无感知地升级或降级协议。

在这些表象之下，HTTP2做了诸多的改进

OpenResty基于Nginx，所以天然地支持HTTP2，但默认情况下并未启用，需要在编译前的configure时使用选项“--with-http_v2_module”开启，例如：

### 第13章 WebSocket服务

“WebSocket”是一种基于TCP的新型网络协议，对应“TCP Socket”，可以理解为运行在Web（即HTTP）上的Socket通信规范。

WebSocket的关注点是实现双方向的实时通信。

### 13.2 服务配置

WebSocket基于TCP通信，但握手利用的仍然是HTTP协议（使用“Upgrade: web-socket”头要求协议升级），所以在建立连接的初始阶段完全兼容HTTP协议（之后就切换到了WebSocket协议），默认端口就是80或443，

### 第14章 TCP/UDP服务

处理HTTP/HTTPS协议的http子系统，配置和代码都写在http{}里。本章将介绍OpenResty中处理TCP/UDP协议的stream子系统，它使用的是stream{}，能够基于TCP/UDP协议开发出更通用的网络服务。

### 14.1 简介

早期的OpenResty只能处理HTTP协议，使用的是ngx_lua模块。在Nginx 1.9.0引入stream子系统后，OpenResty也实现了运行在stream{}里的stream_lua模块。时至两年后的今天，stream_lua模块终于达到了“productionready”状态，可以较好地处理TCP/UDP协议，并已经有了多个实际应用（如纯Lua实现的DNS服务器）。

stream子系统与http子系统拥有相同的基因，但因为它面对的是不透明的二进制数据流，所以在处理方式上略有不同，要求开发者必须自己做协议解析、数据收发等工作。还有一点区别是没有“location”，直接在server{}配置块里定义服务的各种参数。