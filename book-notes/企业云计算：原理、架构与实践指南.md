## 企业云计算：原理、架构与实践指南
> 方国伟等

### 序

2019年1月1日，平安集团启用了新的Logo，用“金融·科技”替代使用了10年的“保险·银行·投资”。这是一个里程碑式的事件，它正式宣告平安集团进入了新的发展阶段。科技已经不再是支撑业务的辅助角色，而是走向前端，与业务深度融合，进而成为平安集团的核心业务。

在科技转型的背后，是传统IT基础架构向云的转型。作为平安集团科技转型的基础，云计算是集团业务创新的技术支撑，一方面为大数据、人工智能等前沿技术提供分布、弹性、触手可得的基础资源；另一方面通过提供安全可靠的海量数据载体、灵活敏捷的开发部署环境，在大幅降低开发运维成本的同时实现应用迭代的加速。

### 前言

同时，我提出“搭台唱戏”的构建模式，即我们云创新小组作为云平台建设的底层团队构建一个基础平台（搭台），然后欢迎公司内其他团队一起参与构建云平台服务（唱戏）。我们不希望让其他团队认为云平台只属于我们创新小组，云平台是属于公司的，我们只是牵头建设团队。

### 1.3 云计算赋能企业数字化转型

云计算平台提供的IaaS、PaaS服务将基础设施、常用中间件、数据库服务等应用环境直接作为资源发布在自服务平台中，供开发团队自助、按需获取，从而大大降低开发人员对开发环境和测试环境的部署门槛；而容器技术、微服务架构的引入则从应用架构层面提供了应用快速迭代的基础；

### 4.4 专属服务器DH

专属服务器DH（Dedicated Host）是一个基于虚拟化技术托管的用户独享物理服务器，提供物理隔离、资源独享的单租户环境，独享CPU、内存、磁盘资源，可以在此宿主机上自主规划实例数量。

因此，DH上创建的专属ECS实例相比普通ECS实例可以实现物理隔离及更稳定、可靠的性能，适用于对安全性、隔离性及稳定性要求高的场景

专属服务器相比云服务器ECS具有以下优点：
（1）物理隔离，确保更高安全性；
（2）资源独占，不存在与其他租户争抢资源的问题；
（3）允许自定义服务器集群部署；
（4）能满足更严格的合规和监管要求；
（5）允许自带许可证上云。

### 7.1 高可用性设计

云服务器ECS服务的可用性不低于99.95%!，(MISSING)表明在一个月（假设30天）内，ECS云服务出现故障的时间只能最多为30×0.05%!×(MISSING)24×60min=21.6min。

高可用性设计是指通过负载均衡、同城容灾、异地容灾等手段避免单点故障从而有效保障服务持续性的设计。

通常还需要增加异地的冗余实例实现同城+异地容灾，从而实现高可用性。该场景下，需要在访问层增加一个DNS路由切换，用于在意外发生时，将系统访问从同城实例切换到异地容灾实例

当然，不可避免地，利用冗余方式实现的高可用性将导致成本的上升。在生产实践中，需要综合平衡业务需求和成本预算选择合适的高可用设计。

### 7.2 高扩展性设计

比较而言，垂直扩展往往需要重启机器而中断服务，且单机扩展有上限，水平扩展不影响服务的连续性，而且没有实例数量限制。

为了保证Web应用可以水平扩展，首先需要进行应用的无状态设计，实现计算、数据的分离。这里很常见的一个问题是对于用户会话数据的处理。在水平扩展架构下，用户会话数据不能存放于本地，一种解决方案是采用客户端Cookie代替，另一种是将会话数据存放于共享的数据库中。此外，可以考虑开启负载均衡的会话保持功能，保证同一客户端的请求会转发到同一台Web实例上。

### 8.2 消息中间件

4．流式数据处理
消息队列高性能机制等保证了其对于海量数据处理的优越性，因而特别适用于需要实时处理大量数据的领域，如台风预测数据分析、股票数据分析、人工智能数据处理等。

### 8.7 API网关

API网关的主要目的就是将后端的服务API进行暴露和聚合，为内外部调用方提供一个统一入口，从而使得后端的服务API对外可用。在此基础上，API网关还提供了不同层次的功能，可以划分为核心层、增强层、安全层以及监控层等，如图8.28所示。

2）Kong是一个云原生、快速、可扩展和分布式的API网关。更确切地说，Kong是一个在Nginx中运行的Lua应用程序，通过Lua-nginx模块实现。Kong与OpenResty一起发布，OpenResty是Nginx的一组扩展功能模块，包含了Lua-nginx模块。


API网关的核心要点是：所有服务端和消费端都通过统一的网关接入服务，在网关层处理所有的非业务功能。通常，网关也是提供REST/HTTP的访问API。服务端通过API网关注册和管理服务，

2）插件化和可配置
API网关中的处理单元过滤器以插件的方式集成到API网关中，从而可以在无须更改原程序的前提下，提供新功能。如果插件的设计良好，API网关还可以通过配置更改插件的行为。

### 第9章 物联网与边缘计算

（2）以处理复杂运算为特征的高算力物联网设备，用于处理视频、音频等多媒体场景，例如零售超市中智能摄像头、家居场景中可语音交互的智能音箱。

### 9.2 5G网络与边缘计算

．云服务商边缘计算产品
提供云计算服务的信息技术公司近一年也发布了边缘计算产品，如阿里云的Link Edge，百度云的OpenEdge，华为开源的KubeEdge，Rancher开源的K3S等。

### 第10章 云微服务敏捷开发与高效运维

互联网时代流行一个概念VUCA，它用来描述当今的环境充满了Velocity（易变性）、Uncertainty（不确定性）、Complexity（复杂性）、Ambiguity（模糊性）。

首先是应用的基础设施维度，从传统数据中心到IDC托管，再到能够将基础设施以云服务方式提供的云计算平台，企业越来越关注基础架构的敏捷性改造，通过系统基础设施（计算、存储、网络）全面云化实现获取敏捷和弹性的第一波升级。

接着是部署打包维度，从基于物理机部署到虚拟机部署，再到目前的容器。容器的标准化特性简化了微服务的部署，它可以将微服务及其依赖打包到镜像中，并可提供一个独立的工作负载环境单独运行微服务，消除了语言、库或者框架之间冲突的风险，提高了兼容性。

### 10.1 什么是DevOps

最先提出了DevOps的“一个中心，两个基本点”——以业务敏捷为中心，构造适应快速发布软件的工具（Tools）和文化（Culture）。

之后2016年，维基百科对DevOps给出定义并被大家普遍认可和接受。它认为DevOps是Development和Operations的组合词，是一组过程、方法与系统的统称，用于促进开发（应用程序／软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。

为了按时交付软件产品和服务，开发和运营工作必须紧密合作。

从DevOps最早强调解决开发和运维团队间的协同问题，将敏捷思想运用于运维领域，逐步演进到强调解决产品、开发、质量、运营和安全等基于端到端价值流驱动的快速交付问题，当前已演化为一种广义的轰轰烈烈的DevOps文化运动。

### 10.2 企业DevOps实践

企业在落地DevOps实践时，有人关注自动化；有人关注组织文化，其重点是开发和运维的协同；也有人关注小批量的交付。

从价值层面来讲，DevOps的目标是快速交付价值，灵活响应变化。原来的瀑布模型需要等到最后一个环节实施完成才向用户交付价值，而DevOps倡导小批量、增量式的交付价值，这就使交付价值的速度、面向市场的频率得到大幅提升。

第一个维度是自动化，如通过基础设施即代码的方式，将交付扩展到生产的环境；第二个维度是度量，从运维侧暴露一些日志、监控数据等相关信息到开发侧，形成有效的反馈；第三个维度是文化，建立责任共担的机制，促进合作；第四个维度是共享，将运维侧获取到的知识注入开发侧，如把安全需求、监控需求等非功能需求，加入到产品的Backlog中。

### 10.3 微服务开发框架

传统的单体式架构在应对大型复杂的系统时力不从心，所有的业务模块耦合在一起，代码会变得庞大并且难以维护，应用启动缓慢，开发迭代速度降低，无法满足不断变更的市场需求；

微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（通常是基于HTTP的RESTful API）。

定义中可以看到微服务具有以下优势：
（1）应用被划分为多个服务，每个服务都通过轻量级协议通信，单个服务变得易于开发和维护，快速响应业务需求；
（2）每个服务都可以针对自身情况选择开发语言和技术栈；
（3）每个服务均可以独立部署，使得持续换部署成为可能。

任何事物都具有两面性，微服务应用也具有以下挑战：
（1）不同服务有独立的数据库，导致数据不一致的问题；
（2）不同服务开发团队需要互相协作，沟通成本大；
（3）问题定位复杂，单体应用拆分成多个服务，查询问题日志难度大；
（4）服务间有依赖关系，修改某个服务可能波及其他服务。

使用Spring Cloud，开发人员可以应用这些模板搭建应用，并且在任何分布式环境下都能工作良好，小到笔记本电脑，大到数据中心和云平台，整个生态体系庞大而稳定，社区活跃。

Service Mesh以Istio微服务框架为代表，号称下一代微服务框架。Istio将服务通信层下沉为基础设施层，实现为轻量级代理，通常以SideCar形式与应用程序部署在一起。

（1）连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB测试和红黑部署等功能；（2）安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；（3）控制（Control）：应用用户定义的策略，保证资源在消费者中公平分配；（4）观察（Observe）：查看服务运行期间的各种数据，如日志、监控和追踪，了解服务的运行情况。

微服务网关（PAFA-Cloud Router）是PAFA-Cloud微服务框架的基础组件之一。从功能上看，它是微服务群的集中出口，负责外部对微服务请求的路由转发、用户认证、服务安全、限流等非业务性功能，其系统架构如图10.14所示。

微服务体系下，服务的数量和配置信息会日益增加，传统的配置方式有本地文件和数据库两种，无法满足开发人员对配置的要求。

微服务的配置中心是将应用系统对配置信息进行集中式的管理，而传统模式下的配置信息管理会分散到各个系统。PAFA-Cloud使用Wizard配置中心作为微服务架构的一个重要部件，可提供统一安全认证、集中式管理配置信息，防止配置信息泄露。另外，配置修改可及时生效以及定向下发，并且支持配置信息动态调整。

6）微服务链路管理微服务链路管理目前包含系统分析、应用监控和链路监控三大功能。

### 10.4 容器服务

Docker的起源要追溯到2008年出现的第一个比较完善的LXC容器技术，LXC是基于Linux内核的cgroups和namespace实现的。Docker诞生于2013年，最早是dotCloud（Docker公司的前身，一家PaaS公司）在一个内部项目中基于LXC实现的，后来用自己开发的LibContainer替换了LXC。

用户从Docker客户端（Docker Client）发送容器的管理请求给Docker守护进程（Docker Daemon），Docker服务器（Docker Server）会接收请求并交给Docker引擎（DockerEngine）处理。

Kubernetes是2014年由Google公司所创建，是Google公司10多年大规模容器管理技术Borg的开源版本，目前是业界应用最广泛的容器集群调度系统。

将容器以服务（Service）方式提供访问，并且提供容器实例间的负载均衡；随时扩展或收缩容器实例规模，提供Service的动态伸缩；可以通过滚动升级（Rolling Update）来便捷升级应用容器的版本，实现服务的不间断访问；提供健康检查和副本集（ReplicaSet），如果容器失效就替换它实现容错自愈等。

Master节点运行三个核心进程：kube-apiserver、kube-controller-manager和kube-scheduler。kube-apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制，并通过etcd集群保存整个集群的状态；kube-controller-manager负责维护集群的状态，如故障检测、自动扩展、滚动更新等；kube-scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的节点上。

Node节点运行两个核心进程kubelet和kube-proxy。kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；kube-proxy负责为Service提供集群内部的服务发现和负载均衡。

容器技术的典型应用场景可以归纳为下面几大类。1．DevOps场景一站式容器化交付，基于代码源自动完成代码编译、镜像构建、灰度发布、容器化部署流程。（1）高效流程管理：更优的流程交互设计，让CI/CD管理更高效，每次集成或交付都会第一时间将结果实时反馈；

面向AI计算的容器服务，在HPC集群上轻松部署机器学习应用、跟踪试验和训练、发布模型。（1）高性能低成本：采用高性能GPU计算实例，并支持多容器共享GPU资源，可以大幅降低AI计算的成本；（2）简化运维：数据部署在分布式存储上，无须关心烦琐部署运维，更专注核心业务；

容器集群可弹性伸缩，根据业务需求和预设策略，自动调整计算资源，使云服务器或容器数量自动随业务负载增长而增加，随业务负载降低而减少，保证业务平稳健康运行。（1）自由灵活：支持多种策略配置，业务流量达到扩容指标，秒级触发容器扩容操作；（2）高可用：自动检测伸缩组中实例运行状况，启用新实例替换不健康实例，保证业务健康可用；

在微服务应用架构下，可以将微服务容器化，充分利用容器引擎的调度、编排、部署和灰度发布的能力，兼具丰富的异常恢复策略，实现敏捷开发和容器化部署，提升业务迭代交付效率。（1）调度策略：服务级别的亲和性调度，跨可用区的高可用性和灾难恢复；（2）负载均衡和服务发现：支持4层和7层的请求转发和后端绑定；（3）微服务监控和弹性伸缩：支持微服务和容器级别的监控，支持微服务的自动伸缩。

### 10.5 敏捷研发流程

5）文档管理
文档管理支持按文件夹、标签、版本等方式对文件进行管理。文件可以是用户在文档管理模块上传的，也可以是用户在卡片上上传的附件。除了提供传统附件上传、下载、更新、删除等功能外，还提供结构化文档Markdown的在线编辑、管理功能。

7）人力工时管理
Wizard卡片上都支持预估工时，研发人员根据需求大小预估工时，卡片完成后，再上报实际工时。可以根据总体预估工时量和组织人员数量，评估各组织、各角色的人员饱和、不足等情况。预估工时和实际工时的差距统计分析能推动团队慢慢把预估做得更加准确。

）统一管理
配置中心提供统一界面管理不同环境（Environment）、不同组件（Component）、不同版本（Version）的配置文件。配置文件具有在线编辑、记录修改历史、对比文件修改、快速复制配置文件等功能。

2）配置发布
用户在配置中心修改完配置，可以直接下发配置，应用端能实时接收到最新的配置，并通知程序做相应的行为改变。可以选择下发所有服务器实例，也可以选择只下发部分实例，达到灰度发布的效果。

Wizard通过流水线把不同作业、任务按一定的流程连接在一起，并且自动化地一步一步地执行，从而实现持续集成（Continuous Integration，CI）和持续交付（Continuous Deployment/Delivery，CD）的能力。Wizard提供可视化的流水线编排能力，用户可以按需定义不同的流水线，一个典型的CI/CD的流水线模型如图10.37所示。

可以看出流水线支持多种触发方式，包括代码触发、定时触发、事件触发、人工触发；并且支持串行（测试部分）、并行（扫描部分）的执行方式。质量门禁在生产发布前进行质量管控，保证生产发布的质量和安全。接下来从几个能力层面详细介绍流水线。

### 第11章 混合云架及实现

混合云（Hybrid Cloud）是在云计算演进到一定程度后出现的一种云计算形态

利用各种云部署模型的技术特点，为提高用户跨云的资源利用率，催生出新的业务。

例如，Gartner认为所有IT环境都是混合的环境，混合IT既包含传统的IT系统也包含云系统（公有云、私有云），

企业基于降低计算和运维成本、数据保密、政策限制和数据安全等原因，一方面希望获取大型云服务厂商的服务；另一方面希望将企业重要数据保存在本地数据中心，也可以访问公有云并利用上面的计算资源，在安全和成本之间取得平衡。

企业采用混合云的架构主要基于以下几个方面考虑。
1）安全性
私有云满足业务敏感数据私有部署的需求，而公有云的计算资源又是私有云无法企及的。在二者不可兼得的情况下，混合云完美地解决了这个问题，它既可以利用私有云的私有部署特性，将内部重要数据保存在本地数据中心，同时也可以使用公有云的计算资源，更高效、快捷地完成工作。简而言之，混合云相比私有云或是公有云更灵活。

3）更节省
混合云可以有效地降低成本。企业可以在公有云与私有云之间灵活选择，将应用程序和数据放在最适合的平台上，获得最佳的利益组合。

总体来说，混合云融合了传统IT、公有云和私有云，是近年来云计算的主要模式和发展方向。它将公有云和私有云进行混合和匹配，以获得最佳的效果。

云适配技术通过在展现层对用户提供统一的API和Console界面、底层适配不同云的API，实现资源的统一管理。多云适配能力（可以适配的不同类型云服务的数量）和服务管理能力（能够管理的不同类型云服务数量）决定了混合云方案的能力。通过抽象统一各个云服务最基本的资源接口，把异构的云资源转化为统一的资源池，再通过统一的适配器为用户提供服务。

2）VPN连接通过IPSec加密通道连接私有云数据中心和云私有网络（VPC）的服务，实现异地容灾和混合云部署。

3）专线接入提供高可靠专用网络接入服务，满足对网络要求苛刻的业务场景。

### 11.2 混合云在金融行业中的实践

结合金融行业的监管特性以及需求规模，我们认为混合云将是未来金融行业的主要发展趋势。而混合云在金融领域建设的主要难点，可总结为以下几个问题。

1．业务系统架构复杂的问题由于金融IT起步较早，存在大量过时的业务系统架构，如单体业务架构，强依赖底层资源的可靠性，不支持高可用架构或者弹性伸缩。

3．金融云安全面临的三大挑战1）网络攻击以DDoS攻击为例的网络攻击，通过巨大的流量拥堵带宽，造成业务中断，从而严重影响企业业务连续性，对企业造成重大安全威胁。

2）应用漏洞威胁开发人员专注于应用功能实现，难免出现安全漏洞，而这些安全漏洞通常是攻击者的攻击入口。

3）安全团队建设成本高企业需要专业安全团队提供安全解决方案设计、安全评估、安全运维以及安全响应，而建设专业安全团队通常意味着高昂的成本。

4．传统研发模式转型DevOps的问题由于传统的研发和部署模式与DevOps存在很大差异，引入CI/CD工具需要对研发和运维人员进行体系培训，并且还需要对现有的开发测试环境进行改造。尽管云平台强调自助服务和自动化集成部署，可以帮助企业提升效率，但只有当企业完全实现高效的DevOps研发系统，才能让客户享受到云平台带来的价值。

（4）CMDB平台：通过CMDB可以查看当前各产品资源使用情况。根据管理页面信息，有效地管理系统中的资源。

用户可以在公有云内的虚拟网络和企业本地数据中心网络之间创建虚拟专有网络（Virtual Private Network，VPN）连接，将本地网络配置扩展到平安云上的虚拟专用网络，使得云上资源可如同现有企业网络的一部分而运行；也可以通过专线连接方式，实现本地网络扩展。

用户数据中心与云上VPC通过公网加密连接，安全可靠，同时平安云使用标准IKE（密钥交换协议）和IPSec协议对数据包进行封装，进一步保证了数据传输的安全可靠。

### 第12章 云运维管理

就像Linux的文件系统，用户只要掌握简单的文件读写技能，就可以在不同的文件系统操作文件，不必关心文件系统下具体的厂商硬件。能在EXT4或NFS执行同样的文件操作，能在不同厂商的硬件设备执行数据持久化，都是因为Linux操作系统实现了这些兼容。

管理10台机器和10万台机器是完全不同的概念，以安全补丁为例，一旦发现必须快速修复，否则可能面临数据丢失、平台崩溃的风险，运维必须争分夺秒保障平台安全。如果只有数十台机器，手动操作可以在很短时间内完成，而对于10万级别的规模，极易引发安全事故。因此，在大规模的场景下运维，效率显得尤为重要。

3）技术多
构建一个云平台涉及大量技术，在网络、计算、存储虚拟化的基础上，每个领域都需要专业的团队去实现，其中涉及大量细分技术。

Container技术的发展又将Flannel、Calico等网络方案呈现在我们眼前，各种Tunnel技术、路由协议、XoverX等名词让人眼花缭乱。

不同团队可能选用不同的技术栈，底层出于性能要求可能偏向于使用C/C++/Rust，业务层出于开发效率可能会选择Java/Go/Python，前端出于灵活展现以及兼容性要求会基于JavaScript/TypeScript的各种衍生框架开发，部署形态从虚拟机到容器、无服务器架构设计从单体到微服务、服务网络等，编排技术从几家争鸣到Kubernetes成为事实标准，数据库从RDBMS到NoSQL再到NewSQL。

### 12.2 云运维管理演进

通过自动化“软件交付”和“架构变更”的流程，使构建、测试、发布软件更加高效、可靠，强调平台化、自动化，以效率为先。

开发要协助运维解决问题，由于工作内容不同，开发和运维之间的沟通会出现信息不对等，技能差异也会导致很多无效沟通。一个问题的定位常常需要来来回回不断确认信息，技能差异和信息不对等使得沟通过程要解释一些与问题无关的知识盲点，最终导致部署过程和解决问题的过程需要花费大量的时间。那个时候，一个版本的迭代需要几周时间

将软件生命周期作为一个整体对待，鼓励软件生命周期的全权负责制（Ownership），而不是只对分割后单个阶段负责，提出了“谁构建谁运维（Operating What YouBuild）”思想，如图12.3所示

通过让开发团队也负责运维来实践DevOps原则，将运维责任分配给每个开发团队，而不是独立的运维团队，让开发体验运维工作并激励改进。体会到运维痛点的开发团队有责任通过改变系统设计或者通过代码方式来优化改善，每个开发团队对部署问题、性能问题、容量规划、监控误报等负责。

完整软件生命周期的全权负责制大大激发了开发人员解决问题的动力，开发者具有消除重复工作的天性，通过工具来自动实现具有共同需求的任务来简化工作，如开发负责回滚服务，那么帮助开发检测和执行回滚操作的工具是必不可少的。

Netflix还通过调整组织架构来发挥团队作用，创建了集中式团队，其任务是开发通用工具和基础架构组件，以解决开发团队都会面临的共性问题。

传统的开发变成了负责全生命周期的开发（Full Cycle Developers）。


广度增加了开发人员的认识负荷，长期下去也会造成人员疲惫和懈怠，Netflix通过轮班来缓解这种情况。工具和自动化有助于扩展专业知识，但是没有任何工具可以解决所有问题，在工具的构建上也要评估是否值得花费成本。

SRE团队承担的职责包括可用性改进、延时优化、性能优化、效率优化、变更管理、监控、紧急事件处理、容量规划与管理等。从职责上看，SRE的工作内容覆盖了开发和运维的工作领域。

是自助服务模型，为了应对大规模扩张，每个团队必须能自给自足，发布系统必须能让产品开发团队自己掌控和执行发布；二是追求速度，面向用户的软件组件发布会非常频繁，必须让用户可见的功能快速上线；

大概70%!的(MISSING)生产故障是由变更引起的，SRE的最佳实践经验是通过自动化来完成变更。采用渐进式机制发布，迅速而准确地检测到问题的发生，出现问题时安全、快速地执行回退。这可以有效降低变更给SRE带来的时间成本，通过将人工因素排除在流程之外，减少重复劳动带来的疲劳，大大提高了执行速度和变更安全。

在故障管理方面SRE也提出了很多最佳实践，包括在测试中提前发现问题、随时待命机制、紧急事故处理流程、事故响应机制、事后总结复盘、故障跟踪、应急预案等。评价一个团队的故障管理能力的最有效的指标就是MTTR（平均恢复时间）。人工的介入必然导致MTTR增大，应该尽量避免人工操作。当人工操作不可避免的时候，有效的“运维手册”通常可以使MTTR降为1/3，因此SRE也将大部分工作重心放在“运维手册”的维护上。

监控系统的设计策略方面，SRE认为不应该依赖人来分析告警信息，而是应该由系统自动分析，仅当需要人工干预某种操作时才通知用户。

企业通常需要重点关注三点：异常、性能与容量。其中，异常的来源主要包括变更引起的异常以及日常运行过程中出现的异常，而性能的衡量与容量的度量都需要依靠数据的采集、监控与分析。

而随着智能时代的来临，AIOps（智能运维）应运而生。AIOps是在2016年由Gartner提出的概念。根据Gartner的定义，AIOps是相对传统运维的一种升级和进化后的运维模式，能够实现业务系统的自动化故障智能检测，自动判断异常与告警，从而能够辅助管理者进行故障根源判断和处理，甚至可以挖掘运维数据隐含信息，通过数据变化对未知风险进行预警，如图12.5所示。

企业可以在一些比较简单的故障处理中，尽量让自动运维代替人工运维。而在一些比较复杂的故障场景中，AIOps系统也会为运维人员提供决策依据。

### 12.3 云运维管理实践

有系统上线必经的架构评审流程，有管理IT资产必备的CMDB，有日常运维必用的请求（Request）、变更（Change）、事件及问题（Case）系统，有发布版本所需的集中部署平台，有管理灾备环境的容灾制度，有应对突发异常制定的应急预案，有处理重大故障的UIOC（Urgent Incident Operations Center，紧急事件指挥中心），看起来一切都很完善。

3．变更管理
变更是指变动和更改可能对服务产生直接或间接影响的IT环境的各要素，包括在生产环境和相关测试环境中对环境、设备、系统、网络、系统软件、参数等的改变。所有变更活动都需要制定相关的规范。

变更管理的主要目的是通过确保正确评估风险、授权变更继续以及管理变更计划来最大化成功服务和产品变更的数量，从而控制风险。

配置项（CI）是指公司信息系统的架构组件或与之相关的内容，包括软件、硬件、服务以及相互之间的关系等。配置管理数据库（CMDB）指用于记录配置项全生命周期属性及配置项之间关联关系的数据库。

（2）系统运行状态可视化：当数据中心出现故障时，通过系统运行状态可视化，可以快速获取每个数据中心资源和云服务的当前和历史运行状态，可以查看的信息包括性能容量、关联对象与告警，以及拓扑与各类日志信息等。

（1）采集是指数据采集，着重包含CMDB、日志管理、监控数据、数据仓库四个方面，应用于资源拓扑的查看、性能瓶颈的分析、系统异常的定位等。

1）服务目录管理。
服务目录管理模块主要对事件、服务请求的目录进行管理。系统管理员可根据需求在此处定义相关目录并进行统一管理。
多级目录设置，方便用户快速找到所需上报通道；同时各个目录中定义了多种属性，为各个模块提供丰富的功能支持。如可支持工单自动分派到对应的处理组，所属公司可针对不同组织进行数据隔离，流程配置定义了当前服务子类是否需要转变更、是否需要审核等。

（5）服务请求管理。
服务请求管理主要包括上报请求工单，实现快速交付，提供优质服务。服务请求管理模块流程图如图12.12所示。


### 13.1 云安全概述

（9）数据残留：云租户的大量数据存放在云计算平台上的存储空间中，如果存储空间回收后剩余信息没有完全清除，存储空间再分配给其他云租户使用容易造成数据泄露；当云租户退出云服务时，由于云服务提供商没有完全删除云租户的数据，包括备份数据等，带来数据安全风险。

### 13.3 平安云平台安全

平安云提供了一个基础的授权服务——访问控制管理（Resource Access Management，RAM）。

（2）平安云的东西向网络访问控制。
此处重点介绍两大技术手段：虚拟专有网络（Virtual Private Cloud，VPC）和安全组（Security Group）。