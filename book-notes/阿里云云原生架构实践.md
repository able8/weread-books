## 阿里云云原生架构实践
> 阿里集团 阿里云智能事业群 云原生应用平台

### 序1

2020年云原生已经在互联网、金融、教育等行业得到了广泛应用。比如基于阿里云容器解决方案，钉钉2小时内扩容1万台云服务器，支撑2亿人在线开工；申通快递将核心系统搬到阿里云上，并进行应用容器化和微服务改造，在日均处理订单数量提升的情况下，IT成本降低一半。

### 序3

2020年云栖大会期间，阿里云宣布成立“云原生技术委员会”。除了承担推动阿里集团全面云原生化的职责，阿里云更重要的责任是将阿里巴巴沉淀10多年的云原生实践对外输出，赋能数百万家企业进行云原生改造，提升研发效率，同时降低IT成本，携手客户迈入数字原生时代。

### 前言

如果你想得到从未拥有过的东西，你就得去做从未做过的事。
——托马斯·杰斐逊

支付宝重塑了我们的支付习惯，Netflix彻底颠覆了我们收看电视和电影的习惯，滴滴与Uber改变了我们交通出行的习惯，这一切在十几年前都是不可想象的。

而是告诉读者如何设计、构建和运维一个优秀的云原生应用，让读者了解云原生能为企业带来什么样的实际业务价值。

### 1.1.1 云原生的概念

2006年，亚马逊公司率先推出了弹性计算云（Elastic Compute Cloud，EC2）服务，随后越来越多的企业开始逐步接受云计算这一概念，并将应用逐步迁移到云端，享受这一新型计算方式带来的技术红利。2009年，阿里巴巴率先开始研制具有完全自主知识产权的云产品——飞天操作系统，由此揭开了中国云计算的序幕。

迁移模式中，应用通常会将原来的物理机部署模式改成虚拟机（规格更小）部署模式；存储则选用兼容的块存储或者文件存储；网络使用SLB（Server Load Balancer，服务器负载均衡）替换传统的负载均衡器，构建VPC（Virtual Private Cloud，虚拟私有云）或NAT（Network Address Translation，网络地址转换）网络环境；使用云数据库替换原来的MySQL或SQL Server，或者自行在云上搭建Oracle数据库。

比如，在数据持久性方面，亚马逊AWS的数据持久性可以达到99.9…%!（(MISSING)11个9），阿里云OSS的数据持久性甚至达到了99.9…%!（(MISSING)12个9）；在跨可用区的高可用方面，阿里云RocketMQ的高可用达到了99.95%!，(MISSING)即使整个机房不可用也能继续对外提供消息服务。

在经过CNCF的修改后，最新版云原生的定义为：“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统做出频繁和可预测的重大变更。”[1]

### 1.1.2 云原生是云计算的趋势

从而帮助企业打造具备弹性、韧性、可观测性、API驱动、多语言支持、高度自动化、可持续交付等特性的现代化应用软件。

### 1.1.3 支撑淘宝千亿交易背后的技术平台故事

在2019年“双11”当天，阿里云取得了傲人成绩：交易创建峰值达54.4万笔/秒，消息系统峰值处理量达1.5亿条/秒，实时计算消息处理峰值达25亿条/秒，RPC调用百亿QPS，批处理计算数据量当天达到980 PB。

### 1.2.1 重塑研发流水线

容器可用于对制品进行打包和分发，即结合GitOps和不可变基础设施，可以实现软件运行环境的整体化部署。换句话说，对运行环境的任何变更，都必须提交到Git中，经过版本管理后重新持续集成，形成新版本的制品并进行部署。这样做的好处是，关于软件运行环境的所有变更都有迹可循。任何时候我们都可以查找（checkout）需要的版本，通过脚本构建出对应的制品。

整个过程不仅高度自动化，而且具备版本跟踪和回溯机制，也解决了上文提到的持续发布的挑战问题，减少了CI/CD中的错误发生概率，从而提升了整体的质量和效率。

### 1.2.2 重新定义软件交付模式

相较于传统模式，云原生软件交付模式主要有如下几个变化。
1）利用容器做整体交付。整体交付减少了容器内部组件之间的安装配置工作，随着容器及编排的开源和普及，更多硬件得到支持，使得容器成为软件交付的标准“底座”。

3）声明式API。很多软件交付都是“告诉”系统需要做什么，特别是脚本中往往会写明如何进行部署；而声明式API首先是“告诉”系统期望的目标状态是什么，比如，在这种环境下部署需要用到两个实例，其次才是脚本或工具需要做什么才能交付这个目标状态（即如何做）。

4）尽量采用OpenAPI作为系统间的集成方式。标准化的OpenAPI更有利于系统间的集成，因为OpenAPI有明确的契约描述或接口规格描述，且提供了各种开放的工具，可以用来做IoT（连通性测试）、SIT（集成测试）等。同时，由于其开放接口（比如，基于RESTful）的特性，可以实现快速集成，从而提升集成的效率。

所以，云原生软件交付模式可以方便地提升软件交付过程的自动化程度，更便于企业实施CI/CD，也可以极大地提升交付效率。根据WeaveWorks的统计，在实施了云原生持续交付后，高水平团队的部署频率将提升200倍，同时变更的错误率将降低为之前的1/3，应用恢复的速度将提升24倍，效果非常明显

### 1.2.3 运维模式的升级

配置变更是运维场景下的高频操作。针对配置变更，云原生的理念是提倡采用不可变的基础设施，即任何变化都是基于容器重新生成一个镜像来进行部署，而不是在原有环境下直接变更配置，也就是说，基础设施是只读的。这样做的好处是任何变更都是可版本化的，因此也就更容易维持变更的质量，从而避免各种未记录的变更给系统带来不可知的影响。

此外，传统的运维更多是面向操作的运维，而云原生的运维则是面向观测数据的自动化运维，两者在运维效率和效果上存在非常大的差别，具体说明如下。

Open Tracing可用于跟踪应用对Redis的每次调用是否存在异常；等等。所有这些数据全部整合在一起后作为metrics（度量）信息导出，由Operator通过API自动、实时获取，并将异常的Redis服务器下线、替换或者升级

### 1.2.4 应用架构的升级

2）re-build：这种方式需要重构甚至完全重写应用，比如，把单体架构（Architecture）改为微服务架构，实施存储状态分离，业务实现采用Serverless技术编写，采用事件驱动架构，等等。

### 1.3.3 云原生架构能为企业带来什么价值

1）创新速度加快：依托有强大算力的云基础设施，构建“小步快跑”的微服务化应用，实现模块化迭代和快速试错，同时将每次业务升级的负面影响降到最低；此外，自动化流水线、API集成、业务持续发布，可以帮助内部技术和业务团队之间形成更紧密的合作。目前，对于业务发布频率，最好的企业已做到了秒级发布，即基本上是按需发布，不受任何发布窗口、质量风险的限制，最大化了业务快速推向市场的能力。

3）成本优化：以前开展业务之前需要购买一大堆软硬件，云计算则是典型的按量付费模式，只要在业务需要的时候找云服务提供商开通对应的服务即可，这样可以减少企业的资本性支出（CapEx），将其中的一部分转换到管理支出（OpEx）；同时，由于云服务具备“永远在线”的特性，因此业务的运维成本、风险成本都得以下降，最终实现整体成本的降低。

5）人才结构：云原生技术的大量应用，使企业内部的分工发生了变化，由于大量管理服务（Managed Service）的使用，IaaS、PaaS层组件的运维人员会不断减少，最典型的就是数据库管理员、硬件运维工程师等将会大量减少；总体上，企业内非业务核心的IT人员会不断减少，相应的成本支出会逐步转移到业务的核心相关人员上。

### 1.4 案例：阿里巴巴云原生发展实践

阿里巴巴为什么要做自己的云计算？除了马云的高瞻远瞩之外，还有一个非常现实的原因：作为一家业务飞速发展的电商公司，如果依赖传统的IT设施来支撑亿级并发、PB级数据处理的业务，那么“高昂的IT基础设施成本将拖垮阿里”（时任阿里巴巴首席架构师的王坚博士如是说）。

阿里巴巴的上云也经历了云原生发展的三个阶段：应用架构互联网化阶段（2009—2016，re-build）、核心系统全面云原生化阶段（2017—2019，re-platform）、云原生技术全面升级阶段（2020—，re-build）。阿里巴巴的云原生实践之路如图1-5所示。

### 1.4.1 应用架构互联网化阶段

T4是阿里巴巴在云原生技术底层研发的开始。它是一款于2011年基于LXC（Linux Container）研发的容器产品，主要用于为集团内的应用打包和发布提供技术服务。2015年，T4结合Docker社区的镜像等技术，演变为Pouch，并于2017年捐献给Apache基金会。Pouch的特点是资源占用少、P2P分发、富容器、隔离性好、可移植性高等，非常适用于提升应用的资源使用率。容器帮助阿里巴巴的应用提升了交付效率，同时也让运维更加方便，但是在阿里巴巴集团这么大的规模下，每个容器集群独占物理资源的模式，开始让大家思考和探索如何进一步提升资源的利用率，由此，阿里巴巴的云原生实践逐步进入第二阶段。

### 1.4.2 核心系统全面云原生化阶段

2019年年初，阿里巴巴启动了“云创未来”项目，不到一年时间率先将电商核心系统100%!上(MISSING)云，不仅将几十万的服务器都迁移到了云上，还通过全面的re-platform，打通了集团和阿里云的技术栈，从底层的神龙服务器、存储、网络、容器、Kubernetes，到上层的云数据库PolarDB和OceanBase，以及PaaS层的消息服务、缓存服务、监控服务、日志服务等。这些都帮助应用实现了高效调度和自动化弹性伸缩，降低了应用50%!的(MISSING)计算成本，同时具备了比传统物理机更好的性能。

### 1.4.3 云原生技术全面升级阶段

阿里巴巴深信，云原生是云计算的未来。从2020年开始，阿里巴巴将全面深入进行云原生升级，以帮助核心应用基于云原生技术和产品进行重构，从而打造现代化的云原生应用。这个阶段的重点是基于Kubernetes进一步实现应用与底层的基础设施解耦，全面提升研发、运维效率，降低应用的整体成本。

其中：全托管的Kubernetes服务带来了发布和扩容效率的提升、更稳定的容器运行时、节点自愈能力，结合发布自动化、资源管理自动化等能力可以实现应用与基础设施层的全面解耦；

Serverless极大地降低了开发人员，特别是服务于前端的后端开发人员的运维负担，亚秒级的容器启动速度和单物理机千容器的部署密度降低了Serverless应用的技术障碍；基于OAM的软件交付理念和工具重新定义了内部的DevOps流程，实现了应用的“一键安装、多处运行”。

### 1.5 本章小结

同时云原生也在加速多项技术的融合，包括中间件和容器的技术融合、大数据和数据库的技术融合、开发和运维的技术融合、PaaS层和IaaS层的技术融合。

### 2.1 云原生架构定义

云原生架构可以最大化地剥离云应用中的非业务代码部分，从而让云设施接管应用中原有的大量非功能特性（例如，弹性、韧性、安全、可观测性、灰度等），使业务能够摆脱被非功能性业务中断的困扰，同时具备轻量、敏捷、高度自动化等特点。

云原生架构可以通过与基础设施深度整合与优化，将计算、存储、网络资源管理以及相应的自动化部署和运维能力，交由云基础设施执行，应用自身会因此变得更为灵活，且具有弹性和韧性，从而大大降低管理成本。

### 2.2.1 服务化原则

在软件开发过程中，当代码数量与开发团队规模都扩张到一定程度后，就需要重构应用，通过模块化与组件化的手段分离关注点，降低应用的复杂度，提升软件的开发效率，降低维护成本。

需要将单体应用进一步拆分，按业务边界重新划分成分布式应用，使应用与应用之间不再直接共享数据，而是通过约定好的契约进行通信，以提高扩展性。

有关服务化设计原则的实践在业界已有很多成功案例。其中影响最广、最为业界称道的是Netflix在生产系统上所进行的大规模微服务化实践。通过这次实践，Netflix在全球不仅承接了多达1.67亿订阅用户以及全球互联网带宽容量15%!以(MISSING)上的流量，而且在开源领域贡献了Eureka、Zuul、Hystrix等出色的微服务组件。

### 2.2.2 弹性原则

因此，在云原生时代，企业在构建IT系统时，应该尽早考虑让应用架构具备弹性能力，以便在快速发展的业务规模面前灵活应对各种场景需求，充分利用云原生技术及成本优势。

1）按功能切割应用
一个大型的复杂系统可能由成百上千个服务组成，架构师在设计架构时，需要遵循的原则是：将相关的逻辑放到一起，不相关的逻辑拆解到独立的服务中，各服务之间通过标准的服务发现（Service Discovery）找到对方，并使用标准的接口进行通信。

### 2.2.3 可观测原则

2.2.3　可观测原则
与监控、业务探活、APM（Application Performance Management，应用性能管理）等系统提供的被动能力不同，可观测性更强调主动性，在云计算这样的分布式系统中，主动通过日志、链路跟踪和度量等手段，让一次App点击所产生的多次服务调用耗时、返回值和参数都清晰可见，甚至可以下钻到每次第三方软件调用、SQL请求、节点拓扑、网络响应等信息中。运维、开发和业务人员通过这样的观测能力可以实时掌握软件的运行情况，并获得前所未有的关联分析能力，以便不断优化业务的健康度和用户体验。

要想构建可观测性体系，需要遵循如下三个基本原则。
1.数据的全面采集
指标（Metric）、链路跟踪（Tracing）和日志（Logging）这三类数据是构建一个完整的可观测性系统的“三大支柱”。而系统的可观测性就是需要完整地采集、分析和展示这三类数据。

（1）指标
指标是指在多个连续的时间周期里用于度量的KPI数值。一般情况下，指标会按软件架构进行分层，分为系统资源指标（如CPU使用率、磁盘使用率和网络带宽情况等）、应用指标（如出错率、服务等级协议SLA、服务满意度APDEX、平均延时等）、业务指标（如用户会话数、订单数量和营业额等）。

（2）链路跟踪
链路跟踪是指通过TraceId的唯一标识来记录并还原发生一次分布式调用的完整过程，贯穿数据从浏览器或移动端经过服务器处理，到执行SQL或发起远程调用的整个过程。

### 3.1.2 IDL定义

IDL定义是指通过IDL（Interface Definition Language，接口定义语言）对服务进行规约定义。如Google gRPC、Apache Thrift等，这些都属于IDL范畴。首先，我们需要基于IDL定义对应的服务接口，然后基于这些IDL文件生成与编程语言对应的代码，实现对应的服务接口，或者调用对应的服务。

### 3.1.3 OpenAPI

OpenAPI是基于HTTP REST通信的接口规范，我们可以先了解其详细的规范定义（参考地址为https://swagger.io/specification/），当前规范为3.0（截至2020年10月）。下面介绍一下Kubernetes 1.16.0对应的OpenAPI规范，详细的定义可以访问https://editor.swagger.io/。图3-1所示为Kubernetes 1.16.0对应的OpenAPI规范截屏。

### 3.2 Service Mesh化架构模式

Mesh定义中的关键信息。
1）Service Mesh是基础设施层，在某些场景中可能要与其他基础设施交互，如基础网络、PaaS平台、运维系统等。如Service Mesh产品Istio就非常依赖Kubernetes这一基础设施，当然Istio本身也是基础设施。

2）Service Mesh可用于解决各服务之间的通信问题。当然，服务之间的通信机制是很复杂的，其中包括通信协议、服务的负载均衡等，所以Mesh需要能够支持多种协议的适配需求，同时要能够支持相关的特性，如负载均衡等。

### 3.2.1 Service Mesh之Sidecar模式

Sidecar模式最典型的方案是Istio+Envoy的结构，其中Istio主要负责控制面（Control Plane）的管控，而Envoy则负责数据面（Data Plane）的网络流量转发。两者的结合实现了Istio的4大目标：连接（Connect）、安全（Security）、控制（Control）和观测（Observe），如图3-3所示。

如果有了代理人的介入，应用只需要与附近（127.0.0.1）的代理人创建连接，然后代理人与目标服务创建连接和路由等。也就是说，有了代理人，应用就不用关心与网络相关的工作了。

当发起网络I/O请求时，如果采用同步阻塞的方式，通常要设置连接池和请求超时，以保证应用的快速响应。代理人可以承担起这部分责任，处理连接池和超时等工作。

4.服务调用的可观测性
传统方式下，如果要监测服务调用，我们需要在SDK中做大量工作（如日志记录、链路跟踪、Metrics埋点等），这些工作将导致SDK变得非常庞大和复杂。代理人介入后，服务请求的转发都是通过代理人完成的，相当于有了统一的入口。

Envoy代理主要负责处理网络请求的转发和接收、协议转换、数据采集等工作，这些基本集中在数据面，而如何指挥并协调这些代理人一起工作，就会牵涉控制面的工作。

2）性能损失和资源浪费。对比传统的直连模式，Envoy代理介入后增加了网络请求的跳数（Network Jump）。Envoy代理同时也是一个独立进程，需要使用到内存和CPU等。另外，转发网络请求涉及协议解析等工作，这些都需要花费额外的计算资源。当然，对于中小规模系统，这种性能损失和资源浪费的影响并不大。但如果系统规模比较大，对资源成本比较敏感，对网络调用的性能损失比较在意，那么Istio+Envoy模式可能就不太合适了。当然，我们可以在Istio+Envoy的基础上对性能进行优化，以达到资源和性能的要求，但显然这又会增加一定的开发成本。

### 3.2.2 Service Mesh之服务注册和发现模式

在微服务架构设计中，服务注册和发现模式是一个非常典型的架构模式。我们在服务化架构模式中也提到过服务注册和服务发现的模式。这一模式的典型代表是Java开发者非常了解的Spring Cloud架构体。Spring Cloud典型架构如图3-5所示。

每个微服务应用启动后，都会向服务注册中心进行注册。服务注册中心产品包括Eureka、Console、Etcd等。注册的信息包括微服务的应用名、对外服务的IP地址和端口号、应用健康度检查HTTP URL，还有一些开发者自行设置的tag信息等。

在Spring Cloud架构下，微服务的通信只需要添加对应的@EnableDiscoveryClient Annotation，让应用连接到Registry Server，然后应用向Registry Server查询相关的服务（这个过程就是我们所说的服务自动发现），最后创建一个具有负载均衡能力的RestTemplate，以便访问其他的HTTP REST服务。示例代码如下：



调用其他应用的HTTP REST服务也非常简单，我们只需要将应用名作为HTTP URL的主机名，服务的自动发现机制会自动完成应用到具体IP和服务端口号的替换，这个过程对开发人员来说是透明的。

Spring Cloud实际发布于2015年年初，早于2017年4月提出的Service Mesh概念；其次，Spring Cloud覆盖的范围更广，远远超出了Service Mesh所涉及的范围，如安全认证、配置服务、流式数据处理、Cloud Function、Cloud Task、ZooKeeper和Vault对接，当然还包括与阿里云、亚马逊AWS、谷歌云、微软Azure等知名云服务的对接，从而降低了接入各种云服务的成本。

但如果系统的核心编程语言不是Java，而是Node.js、Go、Python或者Rust等语言，Spring Cloud方案就不太适合了，毕竟要使用其他编程语言开发出类似的体系，工作量非常大。但这也不是完全不可能的，如Go的Micro（网址为https://github.com/micro/micro），其设计思想就与Spring Cloud非常类似。

### 3.3 Serverless架构模式

云厂商推出了基于Serverless架构设计的FaaS平台，可以帮助我们快速部署静态站点、Node.js服务等，而且是按访问量收费的——100万次访问只收费3元，网络流量每兆字节为0.8元。如果月访问量低于10万次，且网络流量低于5GB，则服务完全免费。这样的便利和优惠非常诱人，我们再也不用考虑Nginx配置、Node.js环境安装、脚本管理、安全包更新等，只要使用该平台的命令行工具即可完成发布。

在微服务架构的应用越来越普及的前提下，大多数开发者逐渐接受并采纳了Serverless。在实际的Serverless开发中，由于与容器类技术方案不太一样，Serverless平台并没有通用的规范，所以不同云厂商的Serverless平台的部署方式和API等都不太一样。但是，大家也不用太担心，Serverless平台架构会遵循CNCF Serverless白皮书开发规范。


### 3.6 可观测架构模式

可观测性（Observability）主要是指了解程序内部运行情况的能力。

目前，关于可观测性的架构设计主要涉及三个部分：日志（logging）、度量（Metrics）和追踪（Tracing）。

### 3.6.3 追踪

微服务架构后基本上是分布式的架构设计。一个简单的HTTP请求可能涉及5个以上应用，一旦出现问题，就会很难快速定位。例如，用户反馈会员登录非常慢，基本要花费5秒以上的时间，这种情况该如何定位问题所在？定位问题涉及登录的Web应用、账号验证服务、会员信息服务、登录的安全监控系统，还涉及Redis、数据库等。如果没有一个高效的追踪系统，排查定位问题的复杂度可想而知。

### 3.8 网关架构模式

网关也称统一接入层，主要负责处理南北流向（North-South Traffic）的网络请求，如来自浏览器、手机移动端或合作伙伴等的访问流量都会经由网关转发给具体的业务系统。
网关的作用是统一入口，这一点对于大型系统或微服务架构来说非常重要，比如统一域名和安全证书、流量统计、限流和防攻击等都可以在网关完成。如果将这些直接转交给微服务应用，每一个微服务应用都要重复这些配置操作，这必然会给微服应用带来非常大的负担，同时增加系统的维护难度。

### 3.10 声明式设计模式

说到声明式设计，其实不少人可能每天都在使用声明式设计，那就是Kubernetes。Kubernetes的对象管理yaml格式文件就是声明式设计的一个经典案例。我们只需告诉Kubernetes所要的最终对象状态，至于中间过程是如何执行的，是新建资源还是删除等，并不需要关心。

声明式设计在实际开发中的作用非常大，常见的如与资源管理相关的IaC（Infrastructure as Code，基础设施即代码）。在使用云资源的时候，我们不会在意这个资源是如何创建的，核心关注点只需要放在云厂商是否能在规定时间内保质保量地提供资源。因此，大多数IaC都是声明式设计。

### 3.11.2 单体应用“硬拆”为微服务

但是最核心的还是领域驱动设计（Domain-Driven Design，DDD）的划分思想。
DDD的本质是根据业务属性将系统划分为不同的业务领域，最简单的如电商系统中的会员、商品、交易和物流等。为了配合这些业务的运行，我们需要一些支持系统，如CMS、社交运营平台等。如果涉及个性化推荐的商业需求，大数据和AI平台也是必不可少的。

### 3.11.5 技术架构与组织能力不匹配

另外，微服务化更强调单兵作战的能力。微服务架构是多语言、多技术栈的架构，虽然不需要我们深入了解每一个微服务的编程语言和技术栈，但要求至少掌握相应的开发技术。

为了更好地配合开发团队，基础设施运维团队需要获得更好的PaaS服务（如基于Kubernetes二次开发，或者云厂商提供的PaaS平台）。只有有了充足的保证，运维团队才能工作得更快、更好。

### 4.1 容器技术

由于越来越多的企业开始应用Kubernetes，因此行业将容器视为下一代云原生操作系统。

### 4.1.1 容器技术的背景与价值

容器作为标准化软件单元，可用于将应用及其所有依赖项整体打包，使应用不再受到环境的限制，从而可以在不同计算环境之间快速、可靠地运行。

Docker容器基于操作系统虚拟化技术，具有共享操作系统内核、轻量、无资源损耗、秒级启动等优势，极大地提升了系统的应用部署密度和弹性。更重要的是，Docker提出了创新的应用打包规范，即Docker镜像，它实现了应用与运行环境的解耦，使应用可以在不同计算环境间一致、可靠地运行。

图4-1　传统、虚拟化和容器化三种部署模式的对比

基于Kubernetes，生态社区开始构建上层的业务抽象，比如，服务网格Istio、机器学习平台Kubeflow、无服务器应用框架Knative等。

据统计，容器技术可使企业的产品交付效率提升3～10倍，这意味着企业不仅可以更快速地迭代产品，而且可以降低业务的试错成本。

通过容器技术，企业可以充分发挥云计算的弹性优势，降低运维成本。据统计，借助容器技术，企业可以降低50%!的(MISSING)计算成本。

### 4.1.2 典型的容器技术

自动修复：Kubernetes可以监测集群中所有的宿主机，当宿主机或OS出现故障时，节点健康检查会自动迁移应用；Kubernetes还支持应用的自愈，从而极大地简化了运维管理的复杂度。

·服务发现与负载均衡：通过Service资源发现各种应用服务，结合DNS（域名系统）和多种负载均衡机制，支持容器化应用之间的相互通信。
·弹性伸缩：Kubernetes可用于监测业务上所承担的负载，如果这个业务的CPU利用率过高，或者响应时间过长，就会自动扩容该业务。

### 4.1.3 应用场景案例：申通基于Kubernetes的云原生化

在运维管理上，线上Kubernetes集群全部采用了阿里云托管版容器服务ACK，免去了运维Master节点的工作，只需要制定Worker节点上线及下线的流程即可。

·日志服务：集成日志服务可以帮助研发人员快速定位业务及异常日志。
　·云监控：集成监控能力可以帮助运维和研发人员快速发现故障。

监控体系在同一个Pod里面部署了两个容器：一个是业务容器，一个是Logtail容器。应用只需要按照运维设定的目录将业务日志打包，即可完成监控数据的采集。

### 4.2 DevOps技术

DevOps（Development+Operations）作为一组过程、方法与系统的统称，是云原生概念的重要组成部分，旨在促进开发（应用程序或软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。

### 4.2.2 DevOps的原则与技术

要想实施DevOps，需要遵循一些基本原则，包括文化（Culture）、自动化（Automation）、度量（Measurement）和共享（Sharing）四个方面，可以简称为CAMS（前面四个英文单词的首字母组合）。

（2）自动化
对于持续集成，DevOps的目标就是小步快跑、快速迭代、频繁发布。小型系统运行起来很容易，但大型系统往往会涉及几十人甚至几百人，要让这个协作过程流畅运行，并不是一件容易的事情。

·知识共享：知识共享主要解决两个问题，一是避免某个人成为单点，避免因为该员工休假或离职而导致工作无法正常完成；二是提高团队的集体能力，团队的集体能力要高于团队中个人的能力。

ChatOps的主要作用是让处于同一群组的成员都能够看到正在进行的操作及结果。诸如会议和讨论等各种不同形式的交流都是为了知识共享。从广义上讲，团队协作就是知识不断积累和分享的过程。落实DevOps，努力建设一个良好的文化氛围，并通过工具支持让所有的共享变得更加方便和高效。

·项目协作：包括需求管理、任务管理、版本管理、里程碑管理等能力。

GitOps是IaC运维理念的一种具体的落地方式，它使用Git来存储关于应用系统最终状态的声明式描述。GitOps的核心是一个GitOps引擎，负责监控Git中应用系统的状态。一旦发现应用系统的状态发生了改变，GitOps引擎就会负责把目标应用系统中的状态以安全可靠的方式迁移到目标状态，从而实现部署、升级、配置修改、回滚等操作。

图4-9　GitOps和Kubernetes配合流程示意图

### 4.2.3 应用场景案例：阿里巴巴DevOps实践

阿里巴巴业务众多，每个业务都需要应对外部需求的快速变化。如何充分利用新技术以提高团队的工作效率，一直是研发效能团队奋斗的目标。下面就来介绍阿里巴巴在利用云原生技术改进DevOps流程中的一系列努力和实践。

·探索基于GitOps和IaC的云原生模式下的软件交付方式，规范软件的交付过程，提升软件交付和运维的效率。

### 4.3.1 微服务的背景与价值

过去开发一个后端应用最直接的方式就是，通过单一后端应用提供并集成所有的服务，即单体模式。随着业务的发展与需求的不断增加，单体应用功能变得越来越复杂，参与开发的工程师规模由最初的几个人可能发展到十几人，应用迭代效率由于集中式研发、测试、发布、沟通的模式而显著下滑。为了解决由单体应用模型衍生出的过度集中式项目迭代流程，微服务模式应运而生。

### 4.3.2 微服务的设计约束原则与典型架构

2016年出现了第三代微服务架构，即服务网格，如图4-14所示。原来被模块化到服务框架里的微服务基础能力，从一个SDK（软件开发工具包）演进成为一个独立的进程——Sidecar（边车）。这个变化使得第二代架构中的多语言支持问题得到了彻底解决，微服务基础能力演进和业务逻辑迭代彻底解耦。

第三代微服务架构就是云原生时代的微服务（Cloud Native Microservice）架构，边车进程开始接管微服务应用之间的流量，承载第二代微服务架构中服务框架的功能，包括服务发现、调用容错以及丰富的服务治理功能，例如权重路由、灰度路由、流量重放、服务伪装等。

### 4.3.3 应用场景案例：阿里巴巴的Dubbo实践

Apache Dubbo作为一款源自阿里巴巴的开源高性能RPC（Remote Procedure Call，远程过程调用）框架，其特性包括基于透明接口的RPC、智能负载均衡、自动服务注册和发现、可扩展性高、运行时流量路由与可视化的服务治理。

随着技术的不断演进，Dubbo v3中已经发展出Service Mesh。目前，Dubbo协议已经得到Envoy支持，数据层选址、负载均衡和服务治理方面的工作还在继续，控制层目前也在丰富Istio的服务发现和配置中心。

### 4.4 Serverless

构建Serverless应用程序意味着开发人员可以将精力专注于核心业务代码上，而无须管理和操作云端或本地的服务器或运行时。Serverless真正做到了在部署应用时无须涉及基础设施的建设，自动构建、部署和启动服务。

### 4.4.1 Serverless的技术背景与价值

·自动的弹性伸缩：大幅降低用户资源容量规划的难度。
·按量计费：企业的使用成本得到有效降低，无须为闲置资源付费。
FaaS（Function as a Service，功能即服务）是Serverless中最具代表性的服务形态。它把应用逻辑拆分为多个函数，并通过事件驱动的方式触发执行每个函数

### 4.4.3 应用场景案例：越光医疗巧用Serverless容器提升诊断准确度

之前启动一台机器再部署容器，可能需要10分钟，关闭也需要一定时间。用了ECI之后，计算资源迅速就绪，排队时间缩短了10%!～(MISSING)20%!(NOVERB)

采用Serverless容器之后，运维也变得更加方便，无须管理底层ECS机器资产，也无须管理操作系统和系统镜像，只需要专注于业务应用的容器镜像即可。

### 4.6.1 Service Mesh的技术背景与价值

Service Mesh的出现使得解决问题的思路从之前的框架思维变成了平台思维，将之前SDK中非常固定的内容（比如编程API、协议编解码等）仍然保留在SDK中，其他内容则全部剥离至完全独立的Proxy（即Sidecar）进程中。Proxy的热升级技术将让平台功能的变更对应用完全无感，从而最大程度解决了过去应用与SDK因深度耦合而无法独立演进的问题。此外，SDK中相关功能的剥离实现了应用的轻量化，让应用能够更好地聚焦于业务逻辑本身。

### 4.6.2 Service Mesh的典型技术与架构

虽然Service Mesh因为Proxy的引入而多了两次IPC通信的成本，但随着软硬件结合优化能力的提升，并没有对整体调用延迟带来显著的影响，对于毫秒级别的业务调用而言，其影响基本可以忽略不计。被服务化的应用并未进行任何改造就获得了强大的流量控制能力、服务治理能力、可观测能力、4个9以上高可用、容灾和安全等能力，加上业务因此而具备的横向扩展能力，整体收益要远大于额外IPC通信所支出的成本。

在安全性方面，Service Mesh非常利于实现云原生时代的零信任架构，包括Pod Identity、基于mTLS的链路层加密、RBAC（Role Based Access Control，基于角色的访问控制）、基于Identity的微隔离环境（动态选取一组节点组成安全域）等内容。

### 4.7 分布式消息队列

消息队列作为一种和RPC同样重要的通信机制和架构模式，对解决业务流量的“削峰填谷”、解耦分布式组件、建立事件驱动架构、流式数据处理、系统间集成等都起着关键作用。

### 4.7.1 分布式消息队列的背景与动机

消息队列管理器在将消息从源中继到目标时充当中间人的角色，消息队列的主要目的是提供路由并保证消息的可靠传递；如果发送消息时接收者不可用，那么消息队列会保留消息，直到可以成功传递为止。

常用于应用解耦、异步通信、流量削峰、日志收集、缓存更新、数据同步、事务最终一致性等典型场景。

### 4.7.2 分布式消息队列的典型技术与架构

RocketMQ，作为一款低延迟、高可靠、可伸缩、易于使用的消息中间件，由阿里巴巴研发并贡献给了Apache基金会，并于2017年成为顶级开源项目。RocketMQ是用Java语言开发的，它采用“发布——订阅”模式传递消息，具有高效灵活的水平扩展能力和海量消息堆积能力，近年来获得了国内外越来越多企业的认可。

Kafka是由LinkedIn开发的高吞吐量分布式消息系统，旨在为处理实时数据提供一个统一、高通量、低延迟的平台。Kafka的最大特性是可以实时处理大数据以满足各种需求场景。

### 4.8.1 云原生数据库的技术背景与价值

随着云原生的普及，以及云计算所引发的技术变革，整个世界发生了跨越式的变化，而数据库也在这场变革中获得了新的动力。Amazon于2009年10月发布了RDS（Amazon Relational Database Service，Amazon关系型数据库服务）并深受市场追捧，开启了云托管数据库时代。

云原生数据库是一种通过云平台进行构建、部署并交付给用户的云服务。相较于其他类型的数据库，它最大的不同就是以云原生的形式进行交付，具备传统数据库所不具备的直接访问性和运行时可伸缩性，属于DBaaS（DataBase as a Service，数据库即服务）平台。云原生数据库的易用性、高扩展性、快速迭代、节约成本等特性，为企业提供了增强的可靠性和可伸缩性，很好地解决了企业用户的核心诉求。

### 4.8.2 云原生数据库的典型技术

·提供极致弹性。计算和存储/内存分离，CPU、内存和存储等部件均可实现独立弹性，支持独立扩展，变配速度快，从而满足不断变化的多种业务需求，实现完全Serverless化。

（2）数据库访问传输加密
为了提高传输链路的安全性，用户可以在控制台或者通过API启用SSL（Secure Socket Layer，安全套接层）加密，并安装SSL CA证书到需要的应用服务中，这样应用服务才能通过SSL访问数据库。

SSL链路最核心的问题是证书签发，阿里云数据库SSL证书采用两级CA结构，只签发服务器端证书，SSL只做单向服务器端验证，不做客户端验证。两级CA结构如图4-28所示，可以在官网下载CA证书链接。

（3）数据库透明加密和存储加密
数据库在传输层加密时会使用SSL机制，在存储层则有两种实现方式：落盘加密（Data at Rest Encryption，DRE）和数据库透明加密（Transparent Data Encryption，TDE）。落盘加密是通过基础设施层的云盘加密能力实现的。数据库透明加密是数据库特有的加密方式，即对数据文件执行实时I/O加密和解密，数据在写入磁盘之前进行加密，从磁盘读入内存时进行解密，密钥使用KMS进行管理。所谓透明，是指对应用来说是无感知的，数据在内存中仍然是解密状态。

### 4.12.2 云原生安全的典型技术

零信任的核心思想是默认情况下不应该信任网络内部和外部的任何人、设备或系统，而是需要基于认证和授权重构访问控制的信任基础。

Istio如何实现零信任架构。如图4-45所示，Istio安全架构的首要特点就是全链路都是通过双向mTLS进行加密，其次就是微服务和微服务之间的访问可以进行鉴权，通过权限访问之后还需要进行审计。Istio是在数据层面和控制层面进行分离的，控制层面通过Pilot将授权策略和安全命名信息分发给Envoy，然后由数据层面通过Envoy来进行微服务间的通信。每个微服务的工作负载（Workload）上都会部署Envoy，每个Envoy代理（Sidecar）都会运行一个授权引擎，该引擎在运行时授权请求。当请求到达代理时，授权引擎将根据当前授权策略评估请求上下文，并返回授权结果Allow或Deny。


对于Service Mesh架构的场景，阿里巴巴将身份信息存放在X.509证书的Subject字段中，以此来携带Workload的身份信息，如图4-49所示。

2.DevSecOps
2012年，Gartner首次提出了DevOpsSec的概念，但由于其缩写为DOS，与Dos（拒绝服务）类似，因此该术语在后续研究与实践过程中被调整为DevSecOps。

·安全左移。在研发周期中，安全问题左移一个研发阶段，修复成本就会提升十倍。从研发角度来看，在编码阶段修复一个安全漏洞可能只需要修改一行代码，而上线后就需要经过定位、修复、验证、灰度等多个阶段，这就造成了秒级与天级的时间差距。而安全左移的原则就是尽可能地在早期覆盖安全检查。如果能在编码阶段进行白盒扫描，就不要等到上线前；如果能在测试环境进行黑盒扫描，就不要拖到上线后。

### 5.2.4 ACNA-S4：云原生技术架构视角

（4）可观测性
IT设施需要得到持续治理，任何IT设施中的软硬件发生错误后都要具备快速修复的能力，以避免影响业务，这就需要系统具备全面的可观测性，内容涉及对传统的日志方式、监控、APM、链路跟踪、服务质量（Quality of Service，QoS）度量等多个方面。
（5）韧性能力
韧性能力除了包括服务化中常用的熔断、限流、降级、自动重试、背压等特性之外，还包括高可用、容灾、异步化等特性。

### 5.3.1 6个评估维度

5.3.1　6个评估维度
ACNA云原生架构设计共包含6个关键架构维度（Service+Elasticity+Serverless+Observability+Resilience+Automation，简写为SESORA）

### 6.4 运维人员

包括SRE（Site Reliability Engineer，网站可靠性工程师）在内的运维人员，作为软件成功运行的保障者，也会受到云原生技术和架构的深刻影响，特别是在技术栈、运维工具、监控和错误处理、SLA管理、AIOps等方面，具体说明如下。


1.技术栈
运维人员的技术栈改变，一方面是由于运维的软件采用了云原生技术栈构建而被动引起的，另一方面则是基于主动利用云原生技术和工具构建新的集成、监控、自动化、自愈、性能管理、高可用管理、安全管理、SLA管理、IT资产管理、事件管理、配置管理、变更管理、发布管理、补丁管理等工作和流程而带来的。这里典型的应用场景是利用Kubernetes Operator实施自动化的资源创建、交付和实例迁移操作。

云原生架构特别强调通过IaC和声明式运维来实现运维过程的高度自动化，即使是在拥有几百上千台机器的复杂分布式系统中，也可以自动化处理部署、升级、回滚、配置变更、扩/缩容等操作。而GitOps作为IaC的一个核心落地理念，不仅包含了对系统目标态的描述，而且贯穿了整个变更过程，既符合DevOps的透明化原则，也具备声明式运维的优点。

AIOps是指在运维中利用机器学习和人工智能技术主动分析和预防故障，同时加快故障处理速度。当在大量业务服务和技术组件中实施可观测性操作后，系统将会产生大量的日志、度量和追踪数据，通过实时的机器学习和人工智能技术对这些数据进行分析，可以辅助变更前后异常检测、多个事件的关联性分析和“假阳性”消除、根因分析、自动化异常节点摘除和应急恢复等操作。

### 7.1 完美日记的云原生之路

·通过容器化部署，利用阿里云容器服务的快速弹性优势，实现大促时对资源快速扩容。
·提前接入链路追踪产品，以跟踪分布式环境下复杂的服务调用，定位出现异常的服务，帮助客户在测试和生产中快速定位问题所在并及时修复，从而降低问题对业务的影响。
·使用阿里云性能测试服务，利用秒级流量拉起、真实地理位置流量等功能，以最真实的互联网流量进行压力测试，确保业务上线后稳定运营。

### 8.1 容器技术的发展趋势

基于MicroVM的安全容器占比将逐渐增加，以提供更强的安全隔离能力。虚拟化技术和容器技术的融合已是大势所趋。在公有云层面，阿里云容器服务已经提供了对阿里云袋鼠容器（基于Kata Container开发）引擎的支持，可以运行不可信的工作负载，实现安全的多租户数据隔离。

值得关注的趋势还有WebAssembly。作为新一代可移植、轻量化的应用虚拟机，WebAssembly在IoT、边缘计算、区块链等场景中有良好的应用前景。WASM/WASI（Web Assembly/WebAssembly System Interface）可实现容器跨平台，

### 8.3 Serverless发展趋势

4.更小的镜像实现更快的分发速度
Serverless平台要求应用的镜像足够小，以实现快速分发，同时要求应用的启动时间极短。虽然在这些方面Java与Node.js、Python等语言之间还存在一定的差距，但我们可以看到Java社区所做的努力，其通过Java 9模块和GraalVM Native Image等技术不断“减肥”，主流框架Spring也开始拥抱GraalVM，而且新的框架（比如Quarkus和Micronaut）也在进行新的突破。

5.解决FaaS状态传递的中间层研究
由于函数之间串联需要状态传递，函数处理需要与外部存储进行频繁交互，因此未来Serverless在函数场景下的最大挑战是由上述因素带来的时延放大问题。在传统架构中，这些过程在一个程序进程内部就可以处理完毕。解决这些挑战需要用到可计算中间层（加速层），可计算中间层是未来学术研究和产品攻坚的方向之一。

### 附录A 阿里云云原生产品介绍

3.应用配置管理
应用配置管理（Application Configuration Management，ACM）是一款应用配置中心产品，可用于实现在微服务、DevOps、大数据等场景下的分布式配置管理服务，保证分布式应用的配置实现快速推送和安全变更。

7.链路追踪
链路追踪（Tracing Analysis，TA）为分布式应用的开发人员提供了完整的调用链路还原、调用请求量统计、链路拓扑、应用依赖分析等工具，能够帮助开发人员快速分析和诊断分布式应用架构下的性能瓶颈，提高微服务时代的开发诊断效率。

9.性能测试服务
性能测试服务（Performance Testing Service，PTS）是一款云化测试工具，可提供应用性能测试、API调试和监测等多种能力，紧密结合监控、流控等产品提供一站式高可用能力，可高效检验和管理应用性能。

2.消息队列Kafka版
消息队列Kafka版（Message Queue@Kafka）是阿里云基于Apache Kafka构建的高吞吐量、高可扩展性分布式消息队列服务，广泛应用于日志收集、监控数据聚合、流式数据处理、在线和离线分析等业务，是大数据生态中不可或缺的中间件产品。对于阿里云提供的Kafka全托管服务，企业无须部署和运维，服务更专业、更可靠、更安全。

3.消息队列AMQP版
消息队列AMQP版（Message Queue@AMQP）是由阿里云基于AMQP标准协议自研的消息队列服务，完全兼容RabbitMQ开源生态及多语言客户端，可提供分布式、高吞吐、低延迟、高可扩展的云消息服务。

1.弹性容器实例
弹性容器实例（Elastic Container Instance，ECI）作为Serverless和容器化的弹性计算服务，无须管理底层ECS（Elastic Compute Service）服务器，提供打包好的镜像即可运行容器，并且只需要为容器实际运行所消耗的资源付费。ECI为企业提供完全兼容Kubernetes的API和运行环境，满足企业既希望通过Kubernetes原生的方式管理容器，又不想运维Kubernetes集群的诉求，使企业以Kubernetes原生的方式获得面向容器的Serverless能力。


### 附录B 常见分布式设计模式

.访问令牌模式
访问令牌模式（Access Token Pattern）主要用于在服务调用时识别调用者的身份，然后基于调用者的身份信息进行访问控制、流量管控、计费等操作。典型的访问令牌如JWT（JSON Web Token）。

3.API网关模式
API网关模式（API gateway pattern）是位于客户端和后端服务之间的桥接系统，主要用于协调、处理客户端的请求并返回相应的结果。API网关主要负责服务路由、负载均衡、流量控制、身份验证和安全控制。网关统一采集的数据可为后续的计费、监控、分析、策略、警报和安全防护提供分析的基础。

18.日志聚合模式
日志聚合模式（Log Aggregate Pattern）是从整个公司的基础架构、应用程序、容器、数据库、移动应用等方面采集日志，并保存在一个中央位置。这些日志包含时间戳、来源、状态、严重性等信息，经结构化处理后，可以用于分析和搜索等。

22.微服务架构
微服务架构（Micro Service Architecture）是指将系统划分为多个互相连接的微服务，每个微服务完成某个特定的功能，最终由多个微服务共同完成系统的功能。

25.无服务器架构
无服务器架构（Serverless Architecture）是一种新的云计算模型，是指以平台服务（PaaS）为基础，为构建程序提供一个微型架构，终端客户不需要部署、配置或管理服务器服务，代码运行所需要的服务器服务皆由云端平台提供。其中，最典型的场景就是FaaS。有时无服务器架构也被称为FaaS。

26.边车模式
边车模式（Sidecar Pattern）是指将应用程序的部分功能独立出来，形成单独的进程并运行，然后通过进程间的通信完成功能调用。边车模式允许为应用程序添加额外的功能，但是不需要应用程序进行配置或更改代码。边车应用可为原应用程序提供如可观察性、监控、日志记录、断路器等功能。