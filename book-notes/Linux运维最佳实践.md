## Linux运维最佳实践
> 胥峰 杨俊俊

### 最佳实践1：禁用权威域名服务器递归查询

递归查询，是指在图1-2中角色为￼本地域名服务器上，它代替￼解析器，依次查询￼根域名服务器→￼顶级域名服务器→￼二级域名服务器来获得DNS的解析条目，然后把响应结果发送给￼

迭代查询，是指域名服务器并不直接代替解析器进行依次查询，而是给它返回一个参考列表，这个参考列表里面指出了可以解析这个DNS请求的服务器，由解析器再次对该列表中的服务器进行DNS查询以获取DNS解析结果。

### 最佳实践2：构建域名解析缓存

DNS解析缓存服务，以达到如下的效果。
·优化DNS响应速度。通过缓存DNS的请求结果，后续相同的DNS请求不再通过访问任何外部网络服务器来获得结果，减少了网络访问的延时。
·减少DNS对外部网络的依赖。在缓存周期内，相同的DNS请求不再发生网络通信行为，可以减少短暂的外部网络不可用导致的影响。

### 最佳实践7：掌握BIND监控技巧

系统负载监控。基本的CPU使用率、内存使用率、网络带宽监控。关于主机的基本系统监控，本节不再进行赘述。请

使用dig对named提供的服务进行监控。这一个级别的监控，是对named自身提供的服务的监控。可以通过模拟用户请求的方法，获得named工作是否正常的信息。

### 最佳实践8：架构典型CDN系统

Nginx代理服务器组：使用Nginx的反向代理技术（Upstream），配置为url_hash的方式，提高对后端Squid缓存服务器组的缓存命中率。同时，也能达到屏蔽后端Squid缓存服务器组中单台服务器故障导致的对业务的影响。

·Squid缓存服务器组：根据HTTP协议中有关缓存设置的规定，实现对页面和资源进行缓存的关键功能业务。通过该组服务器，可以实现缓存文件的快速响应和对源站的代理。

### 最佳实践9：理解HTTP协议中的缓存控制：服务器端缓存控制头部信息

·Cache-Control：max-age=86400￼即服务器端通知客户端，你自收到这个文件起的86400秒内，都可以放心使用，不必再重复请求这个URL。

### 最佳实践10：配置和优化Squid

Squid是对HTTP协议遵从性最好的缓存软件，因此它在CDN中得到了大量的部署，是众多CDN公司使用到的核心缓存软件。

Squid以单进程运行，对多CPU的架构支持不好，不能重复利用多CPU处理器代理的高性能。解决这个问题的思路是在部署Squid的服务器上，部署Squid多个实例进程。

对Squid多实例进行负载均衡时，务必使用URL哈希方法。采用这个方法的好处如下。
·增加缓存命中率。相同的URL访问到同一个Squid实例上，可以提高Squid缓存命中率。
·避免Squid上缓存文件的重复。使用URL哈希后，不同的Squid上缓存不同的文件，因此可以大大节省Squid磁盘缓存空间和内存缓存空间。

### 最佳实践11：优化缓存防盗链

·使用HTTP Referer。HTTP Referer是HTTP请求的一个头部，用于标明被请求的资源是在哪个页面中进行调用的。对静态图片资源文件，使用HTTP Referer设置防盗链即可。

·使用生成动态链接的方法。这个方法的本质是首先在页面上产生资源URL的时候，使用动态编程语言，生成类似如下结构http://music1.woyo.com/music1-abcdefghijk.mp3？key=xxxxyyyyzzzzaaaadddd。在缓存节点上收到用户的请求时，对该URL的key进行验证。该方法一般用于视频、音频等比较大的文件的防盗链检查。

具体的校验过程如下：
1）检查防盗链的串（即key）是否存在，如果不存在，则返回校验失败。
2）从防盗链串中取出日期时间，与当前时间比较，如果超出有效期范围（例如，如果与当前时间相减，大于±2小时），则返回校验失败。

3）生成MD5的值，与请求中的A-MD5-KEY相比较，如果不等，则返回校验失败。
4）如果上述步骤都通过，则返回校验成功。
5）如果校验成功，则CDN缓存服务器向用户返回正常的响应。

### 本章小结

CDN技术是目前使用到的优化用户访问体验的最重要手段之一，在用户通过DNS请求后，即被定向到CDN节点。因此，理解和掌握CDN技术，是每个运维工程师的必备技能。本章全面解析了CDN技术，包括从宏观和微观的技术分析、缓存协议解析等。

### 第3章 负载均衡和高可用技术

目前运维工程师需要熟悉和掌握的重要负载均衡（Load Balance）技术和高可用（High Availability）技术

### 最佳实践14：数据链路层负载均衡

单台Memcached服务器的吞吐量可能达到1.3Gbps左右，明显超过了单个网卡的处理能力；此时又不可能替换成10Gbps网卡（因网络架构和成本限制）。数据链路层负载均衡成为唯一可以采用的方案。
·对网卡功能高可用性的要求。

数据链路层的负载均衡实现方案是实施双网卡绑定（Bonding）

### 最佳实践15：4层负载均衡

网络协议的4层是指传输层，包括TCP和UDP等协议。

·模型简单。负载均衡器不需要关心业务逻辑，只进行负载调度、网络转发和对后端服务器的健康检查。
·吞吐量大。依据上条分析，CPU处理逻辑简单，相对于更高层次的负载均衡，可以提供更大的吞吐量。
·应用范围广。工作在4层，所以它几乎可以对所有应用做负载均衡，包括HTTP、数据库、在线聊天室等。

### 最佳实践16：7层负载均衡

7层负载均衡，又称为“内容交换”，是指负载均衡器通过分析应用层请求的数据特征，进行负载均衡调度。

TCP建立以后，客户端开始发送TCP数据（Payload），通过Wireshark的解析，可以看到HTTP请求的一些特征字段，￼是请求的方法，￼是请求的uri，￼是请求的Host信息。在7层负载均衡器实现中，它通过分析例如￼、￼、￼等的信息作为调度的依据，结合后端服务器压力等，进行请求转发。

吞吐量小。依据上条分析，CPU处理复杂，相对于4层的负载均衡，提供的吞吐量较小。
·对后端选择的精细化控制。因为负载均衡器能够解析到应用层特征，所以能够对客户端的请求更加合理地选择，提高后端的执行效率。比如针对域名、目录结构等。

### 最佳实践17：基于DNS的负载均衡

基于DNS的负载均衡方案，有如下特点。
·配置简单，不需要额外的投入。直接在DNS里面指定多个A记录即可。
·DNS的解析缓存问题，会导致被访问到的服务器故障时，切换时间变长。
·一般要配合其他负载均衡方案和监控机制。
基于DNS负载均衡方案的使用场景，可以总结为以下两种。
·可以选择为初期的简单负载均衡方案。
·比较适合于相同业务多机房调度时。如业务，分布在ISP X机房和ISP Y机房，则该方案比较适用。

### 最佳实践18：基于重定向的负载均衡

基于DNS的负载均衡和基于重定向的负载均衡方案十分类似，都是通过第一次请求来获取实际负责处理的后端服务器的信息；不同之处在于，前者一般仅仅返回网络层IP信息或者CNAME等，后者可以提供更高层信息，同时后者的算法更趋于灵活，对业务适配性更优。

HTTP 302重定向，是这种负载均衡方案的一个比较常见的使用方式。

通过302方法，不同用户访问该链接时，按照预先配置的比重（Weight），概率地引导到￼或者￼所示的实际下载地址，从而达到分流的目的。

### 最佳实践20：高可用技术推荐

如果该角色的服务出现故障，则导致整体业务不可用，成为单点故障（Single Point of Failure）。为了避免该问题，需要对该服务进行高可用架构。本节将概要介绍常用的高可用方案，并根据经验进行技术方案的推荐。

在Linux高可用性软件方面，主要有Heartbeat和Keepalived这2种。Heartbeat可以配置使用单播（Unicast）、组播（Multicast）、广播（Broadcast）进行宣告和选举。Keepalived使用组播进行宣告和选举，同时配置相对简捷。

### 第4章 配置及调优LVS

Linux Virtual Server（LVS）的最佳实践。

·IPVS、ipvs、ip_vs是负载均衡器（见本列表第3项）中的内核代码。
·LVS（Linux Virtual Server）是完整的负载均衡器+后端服务器（见本列表第4项）。这些组件组成了虚拟服务器（Virtual Server），从客户端看起来像一台服务器。

·负载均衡器（Director），运行ipvs代码的节点。客户端连接到该节点，然后被转发到后端服务器。
·后端服务器（Realservers），运行实际服务（Services）的服务器，它们实际处理来自客户端的请求。

·转发模式（Forwarding Method）（目前是LVS-NAT、LVS-DR、LVS-Tun），控制和决定负载均衡器以何种方式转发来自客户端的包到后端服务器。

·VIP（Virtual IP，虚拟IP），配置在负载均衡器上，用于客户端访问的IP地址。

LVS是一个4层负载均衡方案，标准的客户端—服务器网络语义被保留下来。每个客户端都认为是直接连接到了后端服务器，同时后端服务器也认为直接连接了客户端。客户端和后端服务器没有办法获知负载均衡器干预了网络链接。负载均衡器不会检查包的内容，不能根据包的内容做出负载均衡判断（例如包里面包括了cookie，那么负载均衡器是不知道的，也不会去关心该信息）。

LVS不是一个高性能计算集群或者分布式计算集群，后端服务器之间互相感知不到，不能协作处理计算任务。

·为了更高的吞吐量。在LVS里面，添加后端服务器的成本是线性的，

·为了冗余。后端服务器可以被管理员从LVS集群中剔除，然后做一些升级工作，最后再加入集群对外提供服务。这样的操作，不会影响客户端。
·为了适应性。如果吞吐量被评估为逐步增加的，或者事件性的陡增，后端服务器的增加可以对用户透明。

### 最佳实践21：模式选择

LVS-NAT基于NAT（网络地址转换）技术，网络数据流程如下。
1）负载均衡器在收到客户端请求后，改写目的IP地址为后端服务器真实IP和/或端口号，转发给后端服务器。
2）后端服务器处理完成后，回复给负载均衡器。
3）负载均衡器改写源IP为虚拟IP，发送给客户端。
由此可见，负载均衡器是串联在整个架构中。

LVS-DR中的DR是Direct Routing的缩写，译为直接路由。

Client发起Arp Request，请求10.1.6.18的MAC地址，

目的MAC￼为负载均衡器LVS1的MAC地址，目的IP￼为虚拟IP。
步骤3　负载均衡器LVS1进行包转发。

从此处的￼和步骤￼的￼对比可以看到，Web1收到的包Ethernnet的目的MAC已经被LVS1修改成了Web1的MAC地址（文件：LVS_Web1_Request_Receive.pcap，Frame 322），如图4-7所示。

从此处的Web1的回包Ethernet的目的MAC￼为Client的MAC，IP层的目的IP￼为Client的IP，可以得知，该回包没有再经过LVS1。

DR（直接路由）的含义：请求经过负载均衡器调度后，后端服务器的响应数据流量直接返回给客户端，回包不经过负载均衡器。

从吞吐量上来看，LVS-DR最高，LVS-NAT最低。
从配置简便性上来看，LVS-NAT最低，LVS-DR和LVS-Tun均较为复杂。

本书推荐在应用中使用LVS-DR模式，这个也是目前运维架构中应用最多的4层开源负载均衡转发策略。

### 最佳实践22：LVS+Keepalived实战精讲

在LVS1和LVS2上，安装ipvsadm和Keepalived。

配置后端服务器Web1和Web2禁用Arp对虚拟IP的响应

配置后端服务器Web1和Web2的虚拟IP

·后端服务器的虚拟IP必须绑定到lo：0上，同时指定子网掩码是255.255.255.255，否则ARP禁用会出现异常。

·Keepalived对后端服务器的健康检查，推荐使用应用层检查方式，另外可以配置Keepalived使用管理员自定义的脚本进行健康检查（MISC_CHECK指令）。

·LVS集群中的负载均衡器，推荐使用16GB及以上内存，同时采用多队列网卡提高网卡吞吐量减少处理延时。
·LVS集群中的后端服务器，根据IO密集型和CPU密集型2类，可以分别使用RAID10、SSD及高频多核CPU来优化。


### 最佳实践24：注意网卡参数与MTU问题

说明IP包分片的原理。以太网的MTU值是1500 bytes，假设发送者的协议高层向IP层发送了长度为3008 bytes的数据报文，则该报文在添加20 bytes的IP包头后IP包的总长度是3028 bytes，因为3028>1500，所以该数据报文将被分片，分片过程如下。

首先计算最大的IP包中IP净荷的长度=MTU-IP包头长度=1500-20=1480 bytes。

### 最佳实践25：LVS监控要点

# cat /proc/net/ip_vs_stats￼

### 最佳实践26：LVS排错步骤推荐

1）ping负载均衡器的真实IP和虚拟IP。判断网络连通性。
2）在负载均衡器上，检查负载均衡器和后端服务器的状态，如

# ipvsadm -ln --sort￼

# cat /var/log/messages* |grep -i keepalived￼

4）检查后端服务器的Arp设置是否生效，使用命令如下：
# sysctl -A |grep -E "arp_ignore|arp_announce"
5）检查后端服务器上的虚拟IP绑定是否成功。使

6）主从负载均衡器切换故障时，需要首先在交换机上确认其学习到的虚拟IP的MAC地址是否被更新成了从的MAC地址，使用命令如下：
show ip arp

### 第5章 使用HAProxy实现4层和7层代理

HAProxy是一款免费开源软件，为高可用和负载均衡提供了一种高效、稳定的解决方案，同时支持TCP和HTTP应用的代理。它特别适合大流量网站，支撑了大量全球访问最频繁的网站。在过去几年里，它成为开源负载均衡方案里面的事实标准，目前在大部分主流的Linux发行版里都自带这个软件。

HAProxy 1.5版本于2014年发布，它具有以下特点。
·原生的SSL支持，同时支持客户端和服务器端的SSL。
·支持IPv6和UNIX套接字（sockets）。
·支持HTTP Keep-Alive。
·支持HTTP/1.1压缩，以节省带宽。
·支持优化的健康检查机制（SSL、scripted TCP、check agent……）。
·支持7层负载均衡（内容交换）。

### 最佳实践27：安装与优化

·HAProxy不要求后端服务器和负载均衡处于同一个网段，在LVS-DR模式下，这个是前提条件。

·HAProxy仅仅要求后端服务器能够在网络上连通，可以跨网段。

默认HAProxy会把日志记录到/var/log/messages文件，本例配置中它单独记录到/app/logs/haproxy.log中。

·leastconn：最小连接数。

·uri：根据uri的部分或者完整uri进行哈希。

·使用基于源地址的负载调度算法。配置指令是：
balance source
·使用基于cookie的技术。配置指令是：
cookie          appsession insert indirect preserve

net.ipv4.ip_local_port_range = 32768    61000 #单个IP可以使用的TCP端口范围是32768到61000

在代理了多台（如20台以上）后端服务器并且并发访问量比较大时，需要注意该参数。如果负载均衡器对后端服务器发起的TCP连接数过多，则可能导致负载均衡器本地端口用光（使用netstat统计），无法向后端服务器建立新的TCP连接导致负载均衡失败。
使用如下命令修改该参数的值，增加可用端口号：
echo 1024 61000 > /proc/sys/net/ipv4/ip_local_port_range
在sysctl.conf中进行修改，以便在服务器重启后依然有效：
# echo "net.ipv4.ip_local_port_range=1024 61000" >> /etc/sysctl.conf

option  forwardfor
此时，后端服务器可以使用分析请求中的X-Forwarded-For字段来解析客户端来源IP。

### 最佳实践28：HAProxy+Keepalived实战

以上的章节中，我们学习了单台HAProxy进行负载均衡代理的实践，本节使用Keepalived配合HAProxy构架高可用的负载均衡。

### 最佳实践29：HAProxy监控

对HAProxy的性能采集，可以通过以下方法进行。
1）启用status状态报告。
        stats enable #HAProxy状态监控使用￼
        stats scope   .￼
        stats uri     /admin?stats￼
        stats realm   Haproxy\ Statistics￼
        stats auth    admin:6w5_xbkRGU
2）启用socket状态监控。
在global配置部分加入：
stats socket    /tmp/haproxy.sock

# echo "show stat" |socat /tmp/haproxy.sock stdio￼

在监控层次方面，尽量采用应用层检查的方式，如Nagios自带的check_http插件，Zabbix的Web Scenarios等。

### 第6章 实践Nginx的反向代理和负载均衡

先看看什么是代理（或者正向代理）。在某些组织中，为了节省带宽费用，往往使用Squid Web Cache等代理软件，使得不同的客户端访问同一个静态资源时能够直接从内部缓存获取，以节省公共带宽。这种情况下使用的是正向代理，一般需要在客户端或者浏览器里面特殊设置。

反向代理（Reverse Proxying）是和正向代理（Proxying）相对的概念。
为了提高单个服务器的处理能力和冗余性，往往在某组服务器之前再单独搭建一台代理服务器，业务域名解析到该代理服务器上，由该代理服务器负责向后端转发请求。
反向代理服务器有如下特点。
·成为业务的统一入口，对业务精细化控制比较方便。
·屏蔽不同硬件型号和性能的后端服务器，对客户端形成一致的访问点。
·对后端服务器健康监控，剔除有故障的节点，对客户端展示稳定的接口。
·可以加入缓存功能等，节省后端服务器的计算资源。
·加速不同地域的网络访问等。

Nginx作为一款同时可以做Web服务和反向代理负载均衡的软件，

### 最佳实践31：安装与优化

减少内存访问损耗，提高程序的速度。
·sendfile：对于静态大文件，启用sendfile加速文件读取。
·tcp_nopush：在Linux socket上启用TCP_CORK选项，和sendfile合用，加速大文件读取。

·keepalive_timeout：定义保活时间，一般建议是60s。
·proxy_connect_timeout：Nginx连接后端服务器的超时时间，请设置成5s或以下值。

·最小连接数：下一个请求被转发到当前活动连接数最小的服务器。
·IP哈希：基于客户端IP来哈希，定位到该客户端需要被调度到的后端服务器。

HTTP 1.0和HTTP 1.1的一个重要区别是前者不支持HTTP Keep-Alive。

### 最佳实践32：Nginx监控

性能采集
在Nginx中增加配置项：
    location /ngx_status ￼
    {￼
        stub_status on;￼
        access_log off;￼
        allow 127.0.0.1;#请对应增加需要访问的来源IP￼
        deny all;￼
    }

·active connections：活跃的连接数量。
·server accepts handled requests：总共处理了100021个连接，成功创建100021次握手，总共处理了10054个请求。
·reading：读取客户端的连接数。
·writing：响应数据到客户端的数量。
·waiting：开启keep-alive的情况下，这个值等于active—（reading+writing），意思就是Nginx已经处理完正在等候下一次请求指令的驻留连接。

通过bash脚本可以对此输出进行格式化，然后添加到Zabbix等监控工具中。

### 最佳实践34：Nginx常见问题的处理方法

（1）错误码400 bad request
一般原因：请求的Header过大。
解决方法：配置nginx.conf相关设置如下：
client_header_buffer_size 16k;￼
large_client_header_buffers 4 64k;
根据具体情况调整，一般适当调整值就可以。

（2）错误码413 Request Entity Too Large
一般原因：这个错误一般在上传文件的时候会出现。
解决方法：配置nginx.conf相关设置如下：
client_max_body_size 10m; //根据自己需要上传的文件的大小调整

（4）错误码502 Bad Gateway、503 Service Unavailable
一般原因：后端服务器响应无法处理，业务中断。
解决方法：从后端服务器的日志中获取请求处理失败的具体线索，解决后端服务器的问题。

一般原因：后端服务器在超时时间内，未响应Nginx的代理请求。
解决方法：Nginx中的2个配置项决定了它向后端请求时的超时时间，需要根据后端服务器的实际处理情况进行调整。
proxy_read_timeout 90; #读取超时，默认为60秒￼
proxy_send_timeout 90; #发送超时，默认为60秒

### 最佳实践43：LVS、HAProxy、Nginx、NetScaler的大对比

LVS、HAProxy、Nginx和NetScaler是运维工程师在工作中常见的负载均衡方案

### 最佳实践44：中小型网站负载均衡方案推荐

在日访问量在3000万PV~1亿PV时，可以使用HAProxy+Keepalived→Nginx→Web服务器集群的架构。HAProxy负责TCP负载均衡，Nginx负责7层调度，Nginx可以配置多台进行负载分担。

DR模式的LVS配置可以最大限度地提升吞吐量。

### 最佳实践45：深入理解HTTP协议

（1）TCP连接建立阶段（TCP Connection Establishing Phase），浏览器和网站服务器通过3次握手分别到达ESTABLISHED状态。

另外一种方法是chunked，这时，服务器并不在HTTP响应头部中告诉浏览器本次需要传输的响应体内容大小，而是分多段传输，在最后一段传输内容使用0字节表示传输完毕，这种方法一般用于图片等本身使用chunks存储的静态文件及动态程序输出的内容等。

### 最佳实践46：配置高性能静态网站

·max：指定Expires的值为31 December203723：59：59GMT，Cache-Control的值为10年。
·-1：指定Expires的值为当前服务器时间-1s，即永远过期。
·off：不修改Expires和Cache-Control的值，此为默认值。

随着社交型网站和应用的发展，由用户产生的内容（User-generated Content，UGC）越来越多。其中，数量最多、访问量最大的就是用户上传的图片。对这些图片进行合理控制、剪裁，可以减少存储的使用量，减少用户访问图片的等待时间，提高用户访问体验。

服务器端通过发送Set-Cookie指令，能够让浏览器在后续访问指定域名的页面时，携带该Cookie信息，以能够在服务器端继续识别该用户端的状态，例如是否登录、个性化设置等。如果在访问静态网站时，浏览器依然携带了这些Cookie，那么必然会造成没有价值的数据流量（因为此时服务器端并没有对该Cookie的内容做任何的分析和利用）。在高并发时，这些消耗将被严重放大。

下面以Cookie为例，内容达到556字节，如果每次都携带这些数据访问每个图片、CSS等，那么损耗的带宽是巨大的。
"UOR=,news.sina.com.cn,; SINAGLOBAL=210.51.28.230_1456210015.377336; ULV=1456796149689:7:2:2:61.172.240.228_1456796147.38634:1456796147677; vjuids=-11466645b.1530ce187ce.0.990eaec13d949; vjlast=1456796150; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WW6u.dTAPVwVwPQFnbF4TWO; lxlrttp=1456740474; SGUID=1456211711424_45356052; bdshare_firstime=1456211967248; U_TRS1=000000e4.eced5308.56cc0800.dd1d08b4; _ct_uid=56cc0801.12f95c0d; sso_info=v02m6alo5qztbidlpmlm6adrpqnlKadlqWkj5OEtY6DoLmNo6C1jpOcwA==; ArtiFSize=14; lxlrtst=1456304013_c; rotatecount=1; ALF=1488332149"
解决这个问题的方法是在配置静态文件时，使用和主站完全不同的域名。例如，提供动态内容的网站域名是www.xufeng.info，那么，可以再申请img.xufengimg.info、css.xufengimg.info等域名用于提供图片、CSS等的访问。

### 最佳实践48：配置多维度网站监控

网站进行全方位监控。
·日志监控。
·可用性监控。
·性能监控。

性能监控，是指对网站当前的连接和访问情况进行记录，输出到图表。性能监控能够对当前的业务情况评估提供数据支持，是进行容量规划的必要数据依据。

### 最佳实践49：MySQL配置项优化

·max_connections：如果经常遇到Too many connections错误，说明max_connections值过小。一种常见的情况是，应用程序没有正确关闭连接，导致默认的151个数据库连接被很快用光。但如果该值设置过大（1000或者以上），MySQL收到的并发请求数很大，那么它可能会失去响应。在这种情况下，应用程序层的连接池技术会对这个问题有所帮助。例如PHP MySQL的pconnect方法，Tomcat的JDBC连接池等。

### 最佳实践50：使用主从复制扩展读写能力

主服务器数据库启用二进制日志，主服务器上的修改保存至本地二进制日志。
Master接收到来自Slave的IO线程的请求后，通过负责复制的IO线程根据请求信息读取指定日志指定位置之后的日志信息，返回给Slave端的IO线程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息在Master端的Binary Log文件的名称以及在Binary Log中的位置。

### 第10章 构建企业级虚拟专用网络

VPN（Virtual Private Network，虚拟专用网络）架设在公共共享的基础设施互联网上，在非信任的网络上建立私有的和安全的连接，把分布在不同地域的办公场所、用户或者商业伙伴互联起来。
VPN使用加密技术为通信提供安全保护，以对抗对通信内容的窃听和主动攻击。VPN在今天被广泛地使用到远程互联中。在VPN技术出现之前，不同办公场所互联组建专用私有网络时，企业往往需要花费较多的钱用于租赁专用线路。VPN的出发点是建立虚拟的专用链路，在互联网上进行传输、用加密技术进行安全防护。

### 最佳实践52：常见的VPN构建技术

·PPTP（Point-to-Point Tunneling Protocol，点到点的隧道协议）VPN。
·IPSec（Internet Protocol Security，互联网协议安全）VPN。
·SSL/TLS（Secure Sockets Layer，安全接口层）VPN。

SSL/TLS VPN主要使用以下的虚拟设备。
tun/tap设备：Linux中，提供了2种虚拟网络设备tun/tap设备。通过对这2种设备的读写操作，实现内核和用户态程序的交互。
在Linux环境中，SSL/TLS VPN的典型代表是OpenVPN。

### 最佳实践54：使用OpenVPN创建Peer-to-Peer的VPN

tun和tap是Linux等操作系统中提供的一种虚拟网络设备。tun设备可以理解为Point-to-Point的设备；tap设备可以理解为Ethernet设备。需要注意的是，tun/tap设备不是从物理网卡设备中读取包，而是从用户空间的程序读取包；向该设备写入时，并不实际从物理网卡设备上发出包，而是由内核提交到应用程序。

### 最佳实践59：OpenVPN的排错步骤

步骤3　检查服务器是否打开转发并被防火墙允许。
使用如下命令，确认值是1：
# sysctl net.ipv4.ip_forward￼
net.ipv4.ip_forward = 1
使用如下命令，确认chain FORWARD为ACCEPT或者显示指定了tun0的FORWARD为ACCEPT：
iptables -L -n

-A POSTROUTING -o eth1 -j MASQUERADE #VPN服务器内网口启用NAT￼
-A POSTROUTING -o tun0 -j MASQUERADE #VPN服务器隧道口启用NAT￼
COMMIT

步骤5　检查主机的路由表。
在所有参与网络通信的服务器，按照网络数据流的路径，依次使用route或者traceroute命令检查下一跳是否正确。如指向不正确，则修正。
步骤6　使用tcpdump进行分析。
如以上步骤依然无法排除问题，可以使用tcpdump进行抓包。关于使用tcpdump的技巧

### 第11章 实施Linux系统安全策略与入侵检测

Linux系统安全的最佳实践。
·物理层安全措施。
·网络层安全措施。
·应用层安全措施。
·入侵检测系统配置。
·Linux备份与安全。

### 最佳实践60：物理层安全措施

物理安全的保障措施，主要应对以下威胁。
·被盗窃。
·被蓄意破坏。
·自然灾害的威胁。
·人为错误导致的灾难。
·意外事件导致的损坏。

### 最佳实践61：网络层安全措施

首先，对于不需要配置外网IP的服务器，只配置内网地址。这样就可以避免服务器被扫描软件发现，减少被侵入的可能性。
其次，对于有外网的服务器，可以使用防火墙进行保护。
下面的实例，是基于如下的网络层安全需求的。
·允许icmp协议。
·允许所有IP访问本机的80端口Web服务。

Linux中的大部分发行版都有一个内置的、功能强大的防火墙——iptables，更确切地说，是iptables/netfilter。Iptables是用户态的模块，读者可以使用这个模块进行规则配置。

### 最佳实践62：应用层安全措施

·PermitRootLogin：是否允许root用户登录。建议设置为no。同时新增一个用于登录的账号如myadmin，赋予sudo权限。禁用root登录，能直接减少黑客暴力破解的威胁。

PAM（Pluggable Authentication Modules for Linux，Linux可插拔的认证模块）是一组共享库来支持系统对管理员的认证。通过SSHD结合PAM，可以实现以下功能。
·结合LDAP进行统一认证。
·使用动态口令卡，防止静态密码泄露的问题。

黑客通过对URL或者输入表单的字段进行恶意构造，使得应用程序把参数直接构造成SQL语句传入数据库服务器，导致被“脱库”。

### 第12章 实践Zabbix自定义模板技术

目前开源的监控系统也有很多，比如常用的有Nagios、Zabbix、Cacti、Mrtg、Gangila等。各自都有优缺点，但比较下来，Zabbix从功能、性能、架构上来说，都是非常不错的选择。

### 最佳实践66：Zabbix利器Zatree

Zatree的一个主要功能就是提供了一个直观的树形展示页面，在这个页面里面可以非常方便地选择要查看的机器以及它的各项性能，Zatree项目经历了很长一段时间的发展，目前最新版支持Zabbix 2.4.5，功能上增加了单主机监控峰值数据报表和使用了echart图形显示。

### 最佳实践70：SSD定制监控

相比于传统的机械硬盘，SSD硬盘没有磁盘、磁头、磁头臂、马达、永磁铁等，这些烦琐的机械部件，取而代之的是芯片，SSD包含三块主要的芯片，分别是内存芯片、主控芯片、缓存芯片。

·主控芯片：它其实是一颗CPU，它的运算能力由制造工艺、核数数量、频率来决定。主控芯片的运算能力，很大程度上决定了SSD的性能。
·缓存芯片：它并不是所有SSD硬盘都包含的，一般相对高端的SSD型号才有，它的功能与CPU缓存、RAID卡缓存作用相似，都是为了提高性能而配置的。

SSD硬盘的服务器上的应用场景主要分两类。
第一，直接使用，不通过RAID卡，这种场景实际中比较少，因为一般情况下在购买服务器时都配置了硬件的RAID卡。
第二，通过RAID卡，这种场景操作上和普通SAS或者SATA盘一样，先做RAID10，或者RAID6再使用，这种场景比较多。

在SSD硬盘的设备信息里面都会有一项关于使用寿命的记录，使用百分比表示，当这个值变成0%!的(MISSING)时候，那么问题就出现了，SSD盘将变成只读（Readonly）状态，对于大部分应用来说，都会出问题。所以一般情况下，发现SSD硬盘的使用寿命小于10%!时(MISSING)，就应该开始准备更换硬盘，或者迁移业务了。

### 最佳实践71：服务器带外监控：带外邮件警告

先介绍一下，什么是带外管理，通常它是接在服务器主板上的一块芯片，通过这块芯片，管理员可以在不依赖于操作系统的情况下，在它提供的Web界面中完成一些最底层的操作，比如BIOS设置、创建RAID、安装操作系统、查看当前系统运行状态等。
带外管理本身可以采集到详细的硬件信息，同时还提供邮件告警的配置，所以通过带外监控服务器状态，在服务器硬件监控中也是非常实用和常用的。

Postfix是一种电子邮件服务器，用它来做邮件代理配置比较简单，首先需要一台有公网IP和内网IP的机器，最低配置的CentOS 6.5系统服务器即可

### 最佳实践72：理解tcpdump的工作原理

像telnet、tftp等应用程序，其网络通信收发数据，会通过完整的Linux网络协议栈（Linux Network Stack），由Linux操作系统完成数据的封装和解封装。

而tcpdump这一类的应用程序则完全不同，它依赖的是libpcap，libpcap使用的是一种称为设备层的包接口（packet interface on device level）技术。使用这种技术，应用程序可以直接读写内核驱动层面的数据，而不经过完整的Linux网络协议栈。

tcpdump直接从网络驱动层面抓取输入的数据，不经过任何Linux网络协议栈。iptables依赖的netfilter模块，工作在Linux网络协议栈中，因此，iptables对入栈的策略不会影响到tcpdump抓取。但iptables的出栈策略会影响数据包发送到网络驱动层面，因此，它的出栈策略会影响到tcpdump的抓取。

tcpdump和iptables的关系，总结下来有如下2点。
·tcpdump可以抓取到被iptables在INPUT链上DROP掉的数据包。
·tcpdump不能抓取到被iptables在OUTPUT链上DROP掉的数据包。

### 最佳实践79：深度分析运营商劫持的技术手段

运营商的劫持方法，总结起来主要有以下2类。
·基于下载文件的缓存劫持。
·基于页面的iframe广告嵌入劫持。
·基于伪造DNS响应的劫持。

·在HTTP的模型中，请求和应答是成对出现的，即对应一个HTTP请求，只能有一个HTTP响应体。如能排除网络丢包（如拥塞控制、防火墙等）问题导致的重传，则一个HTTP请求引起2个HTTP响应的情况就是劫持。

运营商劫持的方法是：使用旁路设备在近用户端通过分析HTTP请求，获取感兴趣的流量（一般以.zip，.rar，.exe，.patch，.mp3，.mp4，.flv等文件下载、音视频为主），然后引导到自有服务器上。

旁路设备部署方便，不需要改变现有网络结构。只需要在近用户端的路由器上部署端口镜像即可。
·旁路设备不产生单点故障，故障时不会导致用户上网异常。如串联到网络中，则可能因劫持设备故障到而导致大面积用户无法上网而产生投诉。
·外网流量内网化，分担出口带宽压力，节约带宽扩容费用。
·支持移动应用缓存，将大量的移动应用下载到本地，对于现今移动应用流量快速增长的运营商网络来说，可以极大节省下载费用。
·劫持功能可以随时关闭，以应对政策因素等。

这种劫持设备的物理部署节点可以包括如下几个。
·部署在城域网，降低运营商网间结算流量。
·部署在WLAN网络中心。
·部署在小区宽带网络出口。
·部署在集团客户网络出口，降低集团客户对网络出口带宽的需求。

这种劫持带来的问题是：如真实服务器上的文件发生变化，比如版本更新等，则被运营商劫持后可能导致用户下载到老的版本客户端。这恰好是引发本案例的因素。

在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。这些就属于DNS劫持。
基于伪造DNS响应的劫持，因其影响范围较大且容易被用户识别和投诉，运营商用这种方案的越来越少，在近年中发生的次数也呈下降趋势。

### 最佳实践80：在关键文件系统部署HTTPS的实战

HTTPS的工作原理是使用在SSL握手过程中的非对称算法计算出本次会话的对称密钥，然后客户端和服务器端使用该对称密钥算法进行加密和解密。这个过程可以有效防止“中间人”攻击。

### 最佳实践81：禁用连接追踪

虚拟机用户在测试网络连通性时，发现到某主机的网络ping时断时续，丢包严重。同时，它在与该虚拟机同网段的Windows物理机上测试同一IP时，未发生该问题。

在收到保障后，我们首先分析了系统日志/var/log/messages，发现在对应的时间点，有关于nf_conntrack的报错

### 最佳实践82：慎重禁用ICMP协议

·GRE：通用路由封装协议（Generic Routing Encapsulation），规定了如何用一种网络协议去封装另一种网络协议的方法，它是一种应用非常广泛的第三层VPN隧道协议。

公司的大内网使用了GRE VPN技术。GRE隧道需要对IP包再封装，会额外增加GRE报文头（4字节）+外层IP报文头（20字节），总共24字节。而以太网默认的MTU为1500字节，减去GRE封装的24字节，因此VPN网关的MTU应该是1476字节了。在VPN路由器上，网络管理员手动减少了MTU到1400字节。因此，当服务器10.10.60.69发出MTU为1500字节的报文时，被路由器返回了ICMP的报错，并通知服务器以1400字节的MTU重新发包。

实践中，建议不要把iptables完全给禁止，至少应该打开以下访问权限：
iptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPT￼
iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT￼
iptables -A INPUT -p icmp --icmp-type fragmentation-needed -j ACCEPT


### 最佳实践86：系统配置参数优化

参数优化中最常用的就是内核运行参数的调整，在不同的应用场景中会有各自的侧重，通过sysctl-a可以查看当前系统运行内核中的所有配置参数，更改/etc/sysctl.conf文件以便长久保存参数优化项，通过sysctl-p生效配置。

在Web服务器中，服务器承载量和DDOS（分布式拒绝服务）攻击，是比较受关注的两个点，在Linux内核参数配置中，也有对应的配置参数可以优化，以下就来逐一介绍。
1.tcp_max_syn_backlog
在/etc/sysctl.conf中配置项为net.ipv4.tcp_max_syn_backlog，默认的配置大小是1024。

再介绍一下SYN flood攻击，SYN flood也称SYN泛洪攻击，是一种阻断服务器攻击，它的原理就是在TCP三次握手中阻断第三次握手。阻断方式有以下两种。
1）第三次握手过程中，客户端不向服务器返回ACK信息，连接无法建立。
2）第一次握手客户端向服务器发出请求的时候伪造了一个IP地址，使服务器响应这个伪造的IP，伪造的IP不可能给服务器ACK确认，连接无法建立。

在服务器等待客户端ACK确认的时候，在服务器上就会产生SYN_RECV连接也称半开通连接，net.ipv4.tcp_max_syn_backlog参数的配置决定了服务器最大的SYN_RECV连接数量，一旦达到这个最大值，之后再有TCP请求，服务器都不再响应请求了。默认是1024，通常情况下可以配置为2048或者4096。增加net.ipv4.tcp_max_syn_backlog可以增加服务器抗攻击能力，但是同时也会增加服务器的资源消耗。

net.core.somaxconn表示socket连接队列的最大值，通俗地说就是一个监听端口的最大监听队列长度。当客户端和服务器完成TCP三次握手，建立连接之后，服务器应用程序未接管该连接之前，这个状态的socket连接就处于socket连接队列中，应用程序接管之后，该socket连接将从socket连接队列中去除。
举个例子说明，socket连接队列有如一个桶，TCP连接建立之后，socket连接就到这个桶里，然后Web应用程序，比如Apache、Nginx就从这个桶里取建立完TCP连接的socket，一边在放，一边在取，如果Web服务器面临突发的压力，这个队列就能起到一些缓冲的作用。所以在Web服务器压力低的情况下，socket连接队列会很小。配置这个值，可以增加服务器的性能，通常这个值的配置会比net.ipv4.tcp_max_syn_backlog小，比如1000，或者1024也比较常用。

负载就是IO压力，以至于在KVM虚拟化已经非常成熟的当下，DB服务器虚拟化依然是一块最难啃的骨头，在游戏行业，虽然有已经有游戏DB服务器开始运行在KVM虚拟机上，但针对核心业务或者核心数据库，运行在虚拟机里的非常少。

系统一旦开始使用swap分区就会对磁盘带来很大负载，那么DB的性能也将随之降低，所以对于DB服务器，都会禁止系统使用swap空间，配置vm.swappiness=0。

KVM（Kernel-based Virtual Machine，基于内核的虚拟机）虚拟化技术发展至今，已经变得非常成熟和稳定了，KVM也几乎成为所有公有云厂商一致的选择。对于有一定资源和技术实力的公司，很多都会尝试用KVM来搭建属于自己的私有云，虽然现在公有云的选择有很多，但出于安全考虑，敏感系统、重要数据还是不放心直接放到公有云上去。

### 第18章 利用Perl编程实施高效运维

Perl天生是为了处理文本而存在，结合正则表达式可以有效地分析剥离海量数据中的有效成分；同时，使用按需加载文件，可以高效地利用有限的系统内存。

·我们会经常需要写一些服务器批量管理工具，这时再用shell中的for循环逐一执行会导致耗时较长。利用Perl，可以方便地进行多进程编程，极大地提高执行效率。

### 最佳实践87：多进程编程技巧

使用多进程编程，可以得到以下好处。
·最大化服务器执行效率。多进程编程，可以充分利用服务器多CPU的计算能力，提高并发执行的数量，减少任务执行的时间。
·某个子任务超时或者失败不会导致整个任务时间增加。因为使用了多进程，每个进程单独处理一个子任务，这样可以做到隔离子任务间的相互影响，某个子任务的超时和失败，不会影响其他子任务的执行等待时间。

### 最佳实践88：调整Socket编程的超时时间

通过设置合理的超时时间，能够让调用程序快速返回，以执行后续的逻辑，例如进行报警或者状态汇总等。
在Linux中，需要关注两种情况下的超时机制。
·TCP连接建立阶段的超时。内核通过net.ipv4.tcp_syn_retries（默认是5）来控制SYN重传的次数，如图18-1所示，尝试完整个重传次数的时间消耗约93s（文件：timeout.pcap）。

### 第19章 精通Ansible实现运维自动化

如何使用自动化工具Ansible来实现服务器的自动化部署和管理，同样达到提高运维效率的目的。

### 最佳实践92：理解Ansible

Ansible作为目前非常流行运维自动化工具之一，它具有以下几个优点。
·被管理节点无需安装客户端。
·安装配置简单。
·功能模块丰富。
·可扩展性强，可自行开发功能模块。
·使用简单的编排语言yaml完成一系列复杂的任务。

Playbook（编排、剧本）就是这个思想的具体实现。标准化后的任务，编写成对应的Playbook，可以非常方便地维护和反复使用。换句话说，同一件事，你只需编写一个Playbook。执行一下，全部搞定，听着是不是感觉很有意思，下面我们就来朝着这个方向继续。

·ansible：执行Ad-hoc（临时）任务，例如：获取系统运行时间。
ansible 192.168.1.1 -a ‘uptime’
·ansible-doc：查看模块信息及用法，例如：查看copy模块用法。
ansible -s copy

Ansible的工作原理是由Ansible核心模块默认通过SSH协议（同时支持Kerberos和LDAP轻量目录访问协议）将任务推送到被管理服务器执行，待执行完成之后自动删除任务并返回执行结果。

第二，使用ansible-playbook命令，这个命令使用的最多，后面直接跟一个写好的Playbook文件，在Playbook中，可以定义非常复杂的任务。自动化运维，大部分是靠它来实现的，例如：

### 最佳实践93：学习Ansible Playbook使用要点

使用Ansible来执行操作有两种方式，第一，直接使用ansible来执行Ad-hoc（拉丁文中的含义是“临时的”）命令，通常对于一些需要立即执行，但又不具有通用性的任务使用ansible命令直接执行是非常方便的。第二，通过ansible-playbook命令来执行定义好的Playbook，这里的Playbook笔者理解为“编排”，也就是将完成一个的任务的多个操作步骤，集中地写在这个称谓Playbook的文件里面，类似于编一部剧，用一个Playbook把所有的剧情串在一起。

加入了remote_user这个参数，用于指定执行这个Playbook任务所使用的用户，在默认的Ansible配置文件中定义的执行用户是root。remote_user参数可以定义在Playbook的全局，也可以定义在具体的任务中，

为了配合remote_user参数，在完成用户切换之后，如果还需要再次切换到其他用户，或者切换之后再sudo到root用户，Ansible还提供了become：yes运行再次切换用户，become_method：sudo，通过sudo来切换，become_user：otheruser，切换到otheruser

### 最佳实践95：理解Ansible插件

在Ansible原理与架构部分，介绍了Ansible有6大组件，其中一个就是插件。Ansible通过插件的方式，大大提高了灵活性和可定制性。插件又被分为6个不同的类型，具

### 第20章 掌握端游运维的技术要点

端游，即客户端游戏，是传统的依靠下载客户端、在电脑上进行的网络游戏，例如《魔兽世界》、《热血传奇》等。
·手游，即手机游戏。手机游戏是指运行于手机、Pad等移动终端上的游戏软件，例如《我叫MT》、《超级地城之光》等。
·页游，即网页游戏。网页游戏又称Web游戏，无端网游，简称页游。是基于Web浏览器的网络在线多人互动游戏，无须下载客户端，不存在机器配置不够的问题，例如《帝国文明》等。

架构复杂。大型端游服务器端一般有多种角色的程序，如负责游戏客户端网络接入的GameGate（游戏网关服务器）、负责游戏内容计算的GameServer（游戏服务器）、负责地图的Zone（区域）服务器及数据库服务器、计费认证服务器、安全审计服务器、聊天服务器等。

·同时在线人数巨大。如盛大游戏运营的《永恒之塔》、《龙之谷》等网络游戏最高同时在线均超70万。
·玩家接入的网络复杂。有光纤接入的高速网络玩家，也有ADSL接入的小带宽用户。复杂的网络环境，为端游运维提出了更高的要求。

### 最佳实践97：了解大型端游的技术架构

·网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。

·网关服务器在高负载情况下成为通信瓶颈。
·网关的单节点故障导致整组服务器无法对外提供服务。
上述两个问题可以采用“多网关”技术加以解决。

Load Balancer支持TCP层调度。在计算领域，负载均衡是指把工作压力分发到多个计算资源，例如，计算机、计算机集群、网络连接、中央处理器或者硬盘阵列等。负载均衡的目的是，优化资源使用效率、最大化吞吐量、最小化响应时间、避免某个计算资源过载等。使用多个带负载均衡的组件通过增加冗余度来代替一个单一的组件，可以增加可靠性和可用性。负载均衡通常包括专用的软件或者硬件，例如多层交换机或者域名调度系统等。常用的商业硬件如F5 LTM、Citrix NetScaler等以及开源的技术方案LVS、HAProxy等都可以实现。在调度的基础上，同时增加对Server Group中服务器的监控及健康检查机制，如发现基于某些特定配置的监控选项失败，则从调度队列中删除，以屏蔽访问。

对于网络应用而言，并不是一开始就需要负载均衡，当网络应用的访问量不断增长，单个处理单元无法满足负载需求时，网络应用流量将要出现瓶颈时，负载均衡才会起到作用。

·LoginGate：主要负责在玩家登录时维护客户端与LoginServer之间的网络连接与通信，对LoginServer和客户端的通信数据进行加解密、校验。

·GameServer（GS）：主要负责游戏逻辑处理。网络游戏有庞大世界观背景，绚丽激烈的阵营对抗以及完备的装备和技能体系。目前，网络游戏主要包括任务系统、声望系统、玩家PK、宠物系统、摆摊系统、行会系统、排名系统、副本系统、生产系统和宝石系统等。从软件架构角度来看，这些系统可以看成GS的子系统或模块，它们共同处理整个游戏世界逻辑的运算。

·DBServer：主要的功能是缓存玩家角色数据，保证角色数据能快速地读取和保存。由于角色数据量是比较大的，包括玩家的等级、经验、生命值、魔法值、装备、技能、好友、公会等。如果每次GS获取角色数据都去读数据库，效率必然非常低下，用DBServer缓存角色数据之后，极大地提高了数据请求的响应速度

总之，只有客户端、DBServer和GS所保存的SessionKey一致，才能保证协议收到成功反馈。与DBServer通信的服务器主要有GG，GS和LoginServer，DBServer与GG交互的协议主要包括列角色、创建角色、删除角色、恢复角色等，DBServer与GS交互的协议包括读取角色数据、保存角色数据和跳服务器等，DBServer与LoginServer交互的协议主要是用户登录协议，这时候会给DBServer发送SessionKey。

### 最佳实践98：理解游戏运维体系发展历程

此时需要构建一系列批量管理平台，使得运维人员通过操作平台即可管理批量服务器、批量部署游戏程序、开区合服等操作。这个阶段以提高生产率为主要目标。
·可控制阶段。游戏批量部署后，通过构建全方位的监控系统，能够让运维人员快速准确地发现和定位故障，提高运维稳定性。
·可管理阶段。在完成了可操作、可控制的目标后，通过引入ITIL、安全标准、项目管理知识等，建设规范化、标准化的运维体系，在流程和安全性方面全面提升。

### 最佳实践99：自动化管理技术

在设计自动化管理平台时，有以下的规范推荐给读者。
·操作平台基于B-S架构（浏览器-服务器端）。基于B-S架构时，对于运维工程师来讲，不需要安装额外的软件，有个能上网的PC即可，甚至基于移动互联网也可以进行服务器维护，提高灵活性。

### 最佳实践100：自动化监控技术

·游戏客户端质量监控。通过在大量的游戏客户端中植入网络质量监控插件（通过ping等获取rtt），定期上报客户端到游戏服务器端的网络质量情况，进行大数据分析。可以实时获取到玩家网络的访问情况，快速定位区域性或者大规模系统性网络故障。

系统日志的收集和分析。系统日志包括安全日志（/var/log/secure）、通用日志（/var/log/messages），通过监控日志中的关键词输出报警。

·游戏服务器健康检查和性能监控。健康检查，是指对服务器做存活性检查。通过在游戏服务器上部署自主研发的HIDS插件定期主动上报心跳信息。在规定时间内无上报信息时判定服务器异常，从而进行报警。性能监控，是指把服务器最重要的硬件使用率（网卡、带宽、磁盘使用率、IOPS、CPU使用率、Load Average、内存使用率）上报以进行数据收集，作为事中报警和事后分析的重要依据。

·网络设备和流量监控。在机房网络环境中，一般会部署多种异构的网络设备，如思科交换机、华三交换机、Juniper防火墙等，通过SNMP对这些网络设备进行监控，可以以统一的方式获取性能数据和可用性数据。
·IDC网络质量监控。IDC网络质量监控，体现了全国到机房的网络延时的情况。
·IDC机房连通性监控。IDC机房连通性监控，通过IDC之间进行连通性测试，可以获得主干网络的连通性情况。

盛大游戏业务运维监控体系的系统特点如下。
·从客户端到服务器端的完整覆盖。
·支持统一的监控策略配置和完整性检查。
·丰富的监控曲线展示界面。
·海量报警信息的有效关联和过滤。
·与ITIL事件管理紧密结合，报警自动转化为应急响应。
·应急响应工作平台的事件单。
·7×24小时处理。

### 最佳实践101：运维安全体系

在数以万计的游戏玩家中，有正常的合法玩家，也存在这样一些不老实的玩家。
·试图攻击游戏服务器，让游戏服务器无法工作，以泄私愤。
·攻击游戏登录、计费等系统，以获得私利。
·利用游戏bug，刷金币。
·试图获取服务器权限，以谋取更大利益。
这些玩家对端游运维系统造成了重大的威胁，因此需要构建完整的运维安全体系，以最大可能消除这种威胁。

### 第21章 精通手游运维的架构体系

·手游发行商（运营商）：即代理手游CP开发出来的手游产品，在部分渠道或者全渠道发行CP手游产品的公司。一般由手游发行商进行手游运维工作的实施。例如盛大游戏、龙图游戏等。

日最高在线数的承载能力是进行容量规划时需要满足的服务能力。

### 最佳实践104：推荐的手游架构

游要求客户端强联网，一般使用在TCP协议之上实现私有协议。这样的好处是可以实现长连接和提高交互性；手游一般采用弱联网方式，使用HTTP协议进行通信。

目前的大部分手游在设计客户端和服务器端通信模型时，采用了HTTP协议。

·使用HTTP协议更容易利用到现有成熟的周边基础设施，例如通用的负载均衡软件或者硬件等。
·易于实现压缩。HTTP协议本身支持应用程序以外的由Web服务器提供的压缩功能，减少客户端和服务器端的数据传输量。
·利用HTTP的Session和Cookie机制，易于实现会话保持机制。
·易于实现加密。在HTTP层之上，直接使用SSL协议（HTTPS）即可实现关键信息的加密传输。

·负载均衡器使用商业硬件实现。采用商业硬件的负载均衡可以最大化保障业务稳定性。
·负载均衡器使用双机热备（HA），规避单点故障。

### 最佳实践105：手游容量规划

容量规划（Capacity Planning），是指在系统上线前，或者系统运营过程中，通过分析业务走向，对系统需要的各种网络、计算、存储资源进行提前规划和准备，以灵活地应对这种业务变化带来的系统承载能力要求的变化。

手游服务器需要部署在多线机房，由此可以很好地满足用户多种方式上网的需求。

网络带宽规划的数据来源主要包括2个方面，一个是在小规模测试时收集到的玩家平均带宽使用量，以kbps/每玩家计算。另一个是使用机器人（指能够模拟玩家进行游戏内容测试的自动化程序）测试时收集到的类似数据。

手游客户端更新通过接入外部CDN可以适当分担流量压力。

Memcached服务器组为Web服务器组提供缓存服务，同时减轻了数据库的查询压力。Memcached是基于内存的key-value型缓存，无磁盘IO读写，效率非常高。在对Memcached进行容量规划时，需要关注的是热点缓存数据的分布情况。

以MySQL为例，在数据库配置参数方面，主要考虑增加innodb_buffer_pool_size为系统可用内存的60%!。(MISSING)分析数据库表结构设计时，对主键、索引是否完整、有冗余、表引擎的一致性、字段类型的高效性进行分析。SQL语句评估时，考虑对多表联合查询、limit、复杂查询语句进行优化。在无法直接进行SQL语句优化的条件下，可以考虑通过业务逻辑的调整来减小数据库压力（这一步可能涉及游戏策划、产品经理的沟通，一般比较难）。

·使用数据库读写分离技术。数据库读写分离技术，在数据库分库分表的基础上，又进行了一层压力分解。在MySQL中，通过配置主从复制（Replication）可以获得以下的好处：
·在从库上进行读取操作，可以进一步减少主库的读压力。
·在专用的从库上进行数据备份时，不影响在线业务。
·在专用的从库上进行数据分析和挖掘时，不影响在线业务。
·使用SSD提高随机读写iops。手游的大区制，使得数据库的压力被集中起来，同时不同等级的玩家所具有的不同的游戏行为也加剧了对数据库的压力。使用SSD可以最大限度地提高服务器的iops，以应对这种读写压力。

1）在Web服务器上记录玩家客户端的Cookie字符串。
2）分析5min内的Cookie，去除重复值后的数量作为当前在线人数。
3）统计数据写入人数数据库。
4）图表展示。