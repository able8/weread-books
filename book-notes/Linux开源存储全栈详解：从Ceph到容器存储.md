## Linux开源存储全栈详解：从Ceph到容器存储
> 英特尔亚太研发有限公司

### 前言

自1991年Linux诞生，时间已经走过了近三十年。即将而立之年的Linux早已没有了初生时的稚气，它正在各个领域展示自己成熟的魅力。

：“说实话，我学习的热情从来都没有低落过。Just for Fun.

### 1.1 Linux和开源存储

CPU的计算速度越来越快，但是也达到了一定的瓶颈；计算机工艺（基于硅晶体）可以达到7nm和10nm的级别，但是再往更低突破也不太理想，于是转向了多核化发展；CPU对应的缓存级别，从L1到L2再到更多级别的缓存，扩大了缓存的大小，能让更多的数据位于缓存中，从而更好地降低了延迟。

开源软件越来越流行，生态圈发展越来越好，主要是因为互联网企业在广泛使用开源软件，包括开源存储软件，并且向社区提交补丁，以改善代码质量，这样就形成了一个良性循环。互联网企业对于开源软件的使用或验证（所谓的Dogfood测试）极大地提高了开源软件的影响力，让用户意识到由社区维护的开源软件一样可以作为商用软件来使用。

很多互联网企业最初在运营的时候并没有把自己定位为高科技公司。Amazon最初是一家电子商务公司，它很大一部分收入来自书籍的售卖，后来慢慢转型为一家提供云计算、云存储等服务的高科技公司，

### 1.2 Linux开源存储系统方案介绍

存储服务可以分为3类：块存储服务、文件存储服务，以及对象存储服务。

对于块存储服务来说，操作的对象是一块“裸盘”，访问的方式是打开这块“裸盘”，通过逻辑区块地址对其进行读/写操作。对Linux本机访问来说，可以理解为将一块“盘”映射给主机使用。例

文件存储服务，即提供以文件为基础、与文件系统相关的服务，如目录的浏览等。在客户端看到的就是层次结构的目录，目录里面有相应的数据，包括下级目录或文件等。

对象存储采用扁平化的形式管理数据，没有目录的层次结构，并且对象的操作主要以put、get、delete为主。所以在对象存储中，不支持类似read、write的随机读/写操作，一个文件“put”到对象存储之后，在读取时只能“get”整个文件，如果要修改，必须重新“put”一个新的对象到对象存储里。

对象存储是为了克服块存储与文件存储的缺点，并发挥它们各自的优点而出现的。块存储的优点是读/写速度快，缺点是不太适合共享；文件存储的优点是利于共享，缺点是读/写速度慢。所以结合它们各自的优点出现了对象存储，对象存储不仅读/写速度快，而且适用于分布式系统中，利于共享。

“云计算”中的“云”可以简单地理解为任何可以通过互联网访问的服务，那么根据其提供服务的类型，云计算有以下3种落地方式。

底层为Iaas，提供各种基础硬件平台，如计算、存储及网络。PaaS提供中间层的服务，隐藏了服务器、虚拟机等概念，把一切功能服务化。顶层则为SaaS，提供常见的业务服务。针对云计算的三层结构，出现越来越多的云计算平台，其与云计算服务进行整合，为用户提供了更优质的服务。

### 1.3 三大顶级基金会

Linux基金会的核心目标是推动Linux的发展。我们耳熟能详的Xen、KVM、CNCF等，都来自Linux基金会。

### 3.3 文件系统

索引节点对象代表存储设备上的一个实际的物理文件，用于存储该文件的有关信息。Linux将文件的相关信息（如访问权限、大小、创建时间等）与文件本身区分开。文件的相关信息又被称为文件的元数据。

### 5.1 可用性

服务等级协议（Service Level Agreement,SLA），是指在一定开销下，为了保证服务的性能和可用性，服务提供商与用户之间签订的得到双方认可的协议或合同。

这里面的9越多，代表一定时间内服务的可用时间越长、服务越可靠，停机时间越短，反之亦然。也就是说SLA可以简单表示为有几个9的高可用性，9的多少就代表了能够提供高可用的级别有多高。

### 5.2 可靠性

我们知道硬盘经常会出现损坏的情况，损坏了数据就会丢失。我们为了解决这个问题，从软件层面上通常是在分布式系统中存放数据的多个副本。如果其中一个硬盘损坏，上面数据被抹掉，那么其他硬盘上的副本可以接管服务，同时通过复制恢复数据，如Ceph默认存放了3倍的数据。如果我们要存放大量的冷数据，这样做就需要考虑成本的问题。

在实际的生产环境里，单个磁盘发生故障的概率远大于多个磁盘同时发生故障的概率。基于这种情况，一种新的思路是将磁盘分组，把单个磁盘故障的影响范围限制在各个组内，在组内的磁盘出现故障时，重建数据只需要读取组内的磁盘，所以需要的网络流量更少，从而减少对全局的影响。

### 5.3 数据完整性

与累加和校验类似，CRC在数据传输的形式上也可以表示为“通信数据”加上“校验字节”（也可能是多字节）的形式。CRC算法的基本思想是将传输的数据当作一个位数很长的数，将这个数除以另一个数，得到的余数作为校验数据附加到原始数据后面。

CRC32，它产生一个4字节的校验值。在包括WinRAR、WinZip等在内的很多压缩软件中，都是以CRC32作为文件校验算法的。

### 7.4 Ceph可靠性

在一个传统的架构中，客户端是和一个中心化的组件进行对话的，比如网关、代理、API，这些组件充当后续复杂子系统的一个单点接入口。这就对系统的性能和可扩展性带来了限制，而且还引入了单点故障，即如果这个中心化的组件失效，则整个系统将无法工作。

### 第9章 容器存储

原本是没有虚拟机的，所有的应用都直接运行在物理机上，计算和存储资源都难以增减，要么资源不够用，要么就是把过剩的资源浪费掉，所以现在虚拟机被广泛地使用

容器技术出现并逐渐火热，所有应用可以直接运行在物理机的操作系统上，可以直接读/写磁盘，应用之间通过计算、存储和网络资源的命名空间进行隔离，为每个应用形成一个逻辑上独立的“容器操作系统”。

### 9.1 容器

2005年，SWsoft公司发布了OpenVZ，与Solaris Containers类似，OpenVZ通过打了补丁的Linux内核来提供虚拟化、隔离、资源管理和检查点功能。OpenVZ标志着内核级别的虚拟化真正成为主流，之后不断有相关的技术被加入内核中。

2006年，Google发布了Process Container,Process Container记录和隔离每个进程的资源使用（包括CPU、内存、硬盘I/O、网络等），后改名为cgroups（Control Groups），并在2007年被加入2.6.24的Linux内核版本中。

2013年，Docker诞生，Docker最早是dotCloud（Docker公司的前身，是一家PaaS公司）内部的项目，和Warden类似，Docker最初也使用了LXC，后来才使用自己的libcontainer替换了LXC。和其他容器技术不同的是，Docker围绕容器构建了一套完整的生态系统，包括容器镜像标准（Image Spec）、容器Registry、REST API、CLI、容器集群管理工具Docker Swarm等。

2014年，CoreOS创建了rkt，为了改进Docker在安全方面的缺陷，重写了一个容器引擎，相关的容器工具产品包括服务发现工具etcd和网络工具flannel等。

2017年3月，CoreOS和Docker分别将rkt和containerd捐赠给CNCF基金会。

### 9.2 Docker存储

但是与AUFS相比，OverlayFS实现更加简单，效率更高，并且在2014年被正式加入Linux主线内核中。Docker官方强烈建议用OverlayFS取代AUFS。当前最新版Docker支持两种类型的OverlayFS存储驱动：Overlay和Overlay2（Overlay2具有更高的性能和更高的索引节点利用率）。

### 9.3 Kubernetes存储

容器是很轻量化的技术，相对于物理机和虚拟机而言，在等量资源的基础上容器能创建出更多的容器实例。一方面，一旦面对分布在多台主机上且拥有数百个容器的大规模应用时，传统的或单机的容器管理解决方案就会变得“力不从心”。另一方面，由于为微服务提供了越来越完善的原生支持，在一个容器集群中的容器粒度越来越小、数量越来越多，在这种情况下，容器或微服务都需要接受管理并有序接入外部环境，从而完成调度、负载均衡及分配等任务。简单且高效地管理快速增长的容器实例，是一个容器编排系统的主要任务。
而Kubernetes就是容器编排和管理系统中的最佳选择。Kubernetes的核心是如何解决自动化部署，扩展和管理容器化应用程序。Kubernetes起源于Google内部的Borg系统，因为其具有丰富的功能而被多家公司使用，其发展路线注重规范的标准化和厂商“中立”，支持rkt等不同的底层容器运行时和引擎，逐渐解除对Docker的依赖。

设计初衷是在主机集群之间提供一个能够自动化部署、可扩展、应用容器可运营的平台。在整个k8s生态系统中，能够兼容大多数的容器技术实现，比如Docker与Rocket。

Kubernetes属于主从的分布式集群架构，包含Master和Node:Master作为控制节点，调度并管理整个系统；Node是运行节点，运行业务容器。每个Node上运行着多个Pod,Pod中可以运行多个容器（通常一个Pod中只部署一个容器，也可以将一些高度耦合的容器部署在一起），但是Pod无法直接对来自Kubernetes集群外部的访问提供服务。

Master节点上面主要有4个组件：API Server、Scheduler、Controller Manager、etcd。

API Server（kube-apiserver）主要提供认证与授权、管理API版本等功能，通过RESTful API向外部提供服务，对资源（Pod、Deployment、Service等）进行增加、删除、修改、查看等操作都要先交给API Server处理再提交给etcd。

Scheduler（kube-scheduler）负责调度Pod到合适的Node上，根据集群的资源和状态选择合适的节点创建Pod。如

我们通过API Server创建一个Pod，当这个Pod创建成功后，API Server的任务就算完成了，而后面保证Pod的状态始终和我们预期的一样，这个工作是由Controller Manager完成的。
2）Pod

· kubelet：是Master在每个Node节点上面的代理，负责Master和Node之间的通信，并管理Pod和容器。

· kube-proxy：实现了Kubernetes中的服务发现和反向代理功能。在反向代理方面，kube-proxy支持TCP和UDP连接转发，默认基于Round Robin算法将客户端流量转发到与Service对应的一组后端Pod中。在服务发现方面， kube-proxy使用etcd的watch机制，监控集群中Service和Endpoint对象数据的动态变化，并且维护一个Service到Endpoint的映射关系，从而保证了后端Pod的IP地址发生变化时不会对访问者造成影响。

· emptyDir：空目录。在Pod分配到Node上时被创建，属于Node上的本地存储，生命周期和Pod一样，没有持久性，当Pod从Node上被移除时，emptyDir中的数据会被永久删除。
· hostPath：映射Node文件系统中的文件或目录到Pod中。