## 从零开始学Hadoop大数据分析（视频教学版）
> 温春水 毕洁馨

### 前言

随着互联网的发展，人们日常工作和生活中产生的数据越来越多，伴随着信息的爆炸，大数据应运而生。分布式集群对大量数据的存储和分析处理有极大优势，因此Hadoop的各种技术得到了广泛应用和普及。

阐述了大数据和云计算、物联网之间的关系；讲述了Hadoop的起源、发展和意义。

布式协调服务——ZooKeeper，介绍了ZooKeeper的核心概念，包括Session、数据节点（Znode）、版本、Watcher和ACL等；还介绍了ZooKeeper的安装步骤、服务器端和客户端的相关命令，以及Java API访问ZooKeeper的多种操作。

大数据快速读写——HBase，介绍了HBase列式数据库的体系架构、执行原理及安装步骤，还介绍了通过Shell操作HBase，以及基于Java API访问HBase实现数据增加和查询的相关内容。

分布式消息队列——Kafka，介绍了在大数据背景下的分布式消息队列Kafka的相关知识，主要包括Kafka的基本概念、核心组件、Kafka集群安装及应用案例等。

源的内存数据库——Redis

于电商产品的大数据业务分析系统实战，通过一个项目实战案例，详细介绍了数据采集、数据存储、数据清洗、数据转化、数据分析及最终数据的展现过程。

基于个性化的视频推荐系统实战，通过一个项目实战案例，详细介绍了推荐系统的基本概念、协同过滤推荐算法、项目架构、模型构建的详细过程，并对相关核心代码做了详细解读。

### 第1章 初识Hadoop

对大量数据的有效存储管理和计算分析成为了信息行业迫切需要解决的问题。大数据就是基于数据爆炸的现状产生的。

### 1.1.1 大数据技术

从本质上来说，大数据技术是发现大规模数据中的规律，通过对数据的分析实现对运营层决策的支持。

大数据技术面对的是大规模的数据，每一天都会有大批量的数据生成，如何存储与计算这批数据，就是大数据技术要解决的问题。

### 1.1.2 大数据技术框架

大数据技术框架主要包含6个部分，分别是数据收集、数据存储、资源管理、计算框架、数据分析和数据展示

### 1.1.4 大数据在各个行业中的应用

大数据的本质是发现数据规律，实现商业价值。在生活中有很多大数据应用的场景，包括金融、经济、医疗和体育行业等。

### 1.1.5 大数据计算模式

·批处理计算又称为离线计算，是针对大规模历史数据的批量处理，如MapReduce。

·流计算是针对流数据的实时计算，可以实时处理产生的数据。商业版的有IBM InfoSphere Streams和IBMStreamBase，开源的有Storm和S4（Simple Scalable Streaming System），还有一部分是企业根据自身需求而定制的，如Dstream（百度）。

·查询分析计算是针对大规模数据的存储管理和查询分析，如Hive、Cassandra和Impala等。

### 1.1.6 大数据与云计算、物联网的关系

云计算是一种按网络使用量付费的便捷模式，能进入可配置的计算资源共享池（资源包括网络、服务器、存储、应用软件、服务），使资源被利用。

·云计算服务的分类：Saas、Paas和Iaas。

云计算是计算资源的底层，它的主要作用是支撑上层大数据的处理任务。而大数据的主要处理任务则是提升实时交互式查询效率和分析数据的能力。

在物联网应用中有3项关键技术：传感器技术、RFID标签和嵌入式系统技术。

物联网产生大数据，大数据助力物联网。随着物联网的发展，产生数据的终端由PC转向了包括PC、智能手机和平板电脑等在内的多样化终端，因此物联网推动了大数据技术的发展。

物联网是大数据的来源（设备数据），大数据技术为物联网数据的分析提供了强有力的支撑；物联网还为云计算提供了广阔的应用空间，而云计算为物联网提供了海量数据存储能力；云计算还为大数据提供了技术基础，而大数据能为云计算所产生的运营数据提供分析和决策依据。三者的关系如图1.3所示。

[插图]

### 1.2.2 Hadoop简介与意义

·HDFS（Hadoop Distributed File System，分布式存储系统）：是Hadoop中的核心组件之一，除了可以保存海量数据，还具有高可靠性、高扩展性和高吞吐率的特点。

通过Hadoop可以快速搭建自己的分布式存储系统和分布式运算系统，它可以缩短处理数据的时间，同时可以尽量在低成本的情况下完成数据的分析与挖掘。这里说的低成本，主要是因为Hadoop可以基于廉价的普通PC机搭建集群。

### 2.8 Hadoop分布式安装

伪分布式是在一台机器上模拟分布式，主要用于测试；而完全分布式是由两个及两个以上的节点组建的集群，是真正的分布式。

### 2.8.2 完全分布式安装

伪分布式是基于单个节点，而完全分布式是基于两个或两个以上节点完成Hadoop集群搭建。

### 3.1 DFS介绍

由于一台机器的存储容量有限，一旦数据量达到足够的级别，就需要将数据存放在多台机器上，这就是分布式文件系统，又称之为DFS（Distributed File System）。

### 3.1.1 什么是DFS

分布式文件系统DFS是基于Master/Slave模式，通常一个分布式文件系统提供多个供用户访问的服务器，一般都会提供备份和容错的功能。分布式文件系统管理的物理资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连，而非文件系统管理的物理存储资源一定直接连在本地节点上。

### 3.2.1 HDFS的概念及体系结构

HDFS是Hadoop自带的分布式文件系统，即Hadoop Distributed File System。HDFS是一个使用Java语言实现的分布式、可横向扩展的文件系统。

HDFS包括一个名称节点（NameNode）和若干个数据节点（DataNode），属于主/从（Master/Slave）关系的结构模型。其中，名称节点负责管理文件系统的命名空间及客户端对文件的访问，也就是中心服务器。

数据节点一般是一个节点运行一个数据节点进程，其中每个数据节点上的数据实际上是保存在本地的Linux文件系统中，并在名称节点的统一调动下，负责处理文件系统客户端的读/写请求，或删除、创建和复制数据块等操作。

### 3.2.2 HDFS的设计

HDFS的设计主要是为了实现存储大量数据、成本低廉和容错率高、数据一致性，以及顺序访问数据这4个目标。

HDFS适合存储大量文件，总存储量可以达到PB/EB，单个文件一般在几百兆。

因此对于庞大的集群来说，节点发生故障的几率还是非常高的。HDFS遇到上述故障时被设计成能够继续运行且可以不让用户察觉到明显的中断。

HDFS适用于处理批量数据，而不适合随机定位访问。

### 3.2.3 HDFS的优点和缺点

·高容错性：数据自动保存多个副本，副本丢失后自动恢复。

可构建在廉价机器上：通过副本提高可靠性，提供了容错和恢复机制。

·不适合低延时数据访问：寻址时间长，适合读取大文件，低延迟与高吞吐率。

·不适合小文件存取：占用NameNode大量内存，寻找时间超过读取时间。

·并发写入、文件随机修改：一个文件只能有一个写入者，仅支持append（日志），不允许修改文件。

### 3.2.4 HDFS的执行原理

从客户端传入文件读写请求时，NameNode（HDFS的集群管理节点）首先接受客户端的读写服务请求，并根据它保存的Metadata元数据，包括元数据的镜像文件（fsimage和操作日志edits信息）和DataNode（数据存储）通信并进行资源协调，Secondary NameNode进行edits和fsimage的合并，同时DataNode之间进行数据复制。

如果要存储一个大文件，首先要将文件分割成块，分别放到不同的节点，每块文件都有3个副本备份，并且有一个专门记录文件块存放情况的元数据文件以备查询

### 3.2.6 HDFS读文件流程

DistributedFileSystem通过使用远程过程调用（RPC）来调用NameNode，以确定文件起始块的位置。

### 3.2.8 Block的副本放置策略

HDFS的容错性也要求数据自动保存多个副本

第1个副本：放置在上传文件的DN；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点。·第2个副本：放置在与第1个副本不同机架的节点上。·第3个副本：放置在与第2个副本相同机架的节点上。

更多副本：随机节点。

### 3.3.1 对文件的操作

HDFS的命令都在Hadoop的bin目录下，如果已经设置好Hadoop的环境变量，可以直接输入HDFS命令行，常见的相关命令如下。

### 4.1.1 Hadoop 3新特性

Hadoop 3相较于Hadoop 2有一些新特性，包括基于JDK 1.8、HDFS可擦除编码、MR Native Task优化、基于Cgroup的内存隔离和IO Disk隔离，以及支持更改分配容器的资源Container resizing等。

### 4.1.2 Hadoop 3 HDFS集群架构

HDFS集群中包括NameNode、DataNode和Secondary NameNode，具体介绍如下。·NameNode：接受客户端的读写服务，比如文件的上传和下载，保存元数据，包括文件大小、文件创建时间、文件的拥有者、权限、路径和文件名。元数据存放在内存中，不会和磁盘发生交互。·DataNode：简称DN，与NameNode对应，主要用来存储数据内容，本地磁盘目录存储数据块（Block），以文件形式分别存储在不同的DataNode节点上，同时存储Block的元数据信息文件。

### 4.3 什么是HDFS高可用

NameNode存在单点失效的问题。如果NameNode失效了，那么所有的客户端——包括MapReduce作业均无法读、写文件，因为NameNode是唯一存储元数据与文件到数据块映射的地方。在这种情况下，Hadoop系统无法提供服务，为了减少由计算机硬件和软件易错性所带来的损失而导致NameNode节点失效的问题，可以通过搭建HDFS高可用集群来实现NameNode的高可用性。

HDFS高可用是配置了一对活动-备用（active-standby）NameNode。当活动NameNode失效，备用NameNode就会接管它的任务并开始服务于来自客户端的请求，不会有任何明显的中断。

### 4.3.1 HDFS高可用实现原理

当活动NameNode失效，备用NameNode就会接管它的任务并响应来自客户端的服务请求，不会有任何明显中断。实现这一目标需要在架构上作如下修改。

### 4.3.2 HDFS高可用实现

在高可用架构图中的节点包括NameNode、FailoverController、JournalNode、DataNode和ZooKeeper，下面分别介绍每个节点。

NameNode节点主要有两种状态：active和standby。

### 5.1 ZooKeeper的核心概念

在分布式系统构建的集群中，每一台机器都有自己的角色定位。其中最典型的是Master/Slave模式，在这种模式中，所有写操作的机器都可以称为Master机器；所有通过异步复制方式获取最新数据并提供读服务的机器都可以称为Slave机器。在ZooKeeper中，不同于以往的是引入了全新的Leader、Follower和Observer三种角色概念，即ZooKeeper会通过选举选定一台被称为Leader的机器，这台服务器将为客户端提供读写服务。

### 5.1.1 Session会话机制

在ZooKeeper中，一个客户端连接是指客户端和服务器之间的一个TCP长连接。

ZooKeeper对外的服务端口默认是2181，当客户端启动时，新建立的TCP连接也将第一次启动，它能通过心跳检测与服务器保持有效会话，同时还会向ZooKeeper发送请求并接收响应，另外还能够接收来自服务器的Watch事件通知。

### 第6章 分布式离线计算框架——MapReduce

Hadoop中有两个重要的组件：一个是HDFS，另一个是MapReduce，HDFS用来存储大批量的数据，而MapReduce则是通过计算来发现数据中有价值的内容。

### 6.1.2 MapReduce的应用场景

·单词统计。·简单的数据统计，比如网站PV和UV统计。·搜索引擎建立索引。·搜索引擎中，统计最流行的K个搜索词。·统计搜索词频率，帮助优化搜索词提示。·复杂数据分析算法实现。

·实时计算，MapReduce不合适在毫秒级或者秒级内返回结果。·流式计算，MapReduce的输入数据集是静态的，不能动态变化，所以不适合流式计算。

### 6.2.1 单词统计实例

·Split阶段，首先大文件被切分成多份，假设这里被切分成了3份，每一行代表一份。·Map阶段，解析出每个单词，并在后边记上数字1。·Shuffle阶段，将每一份中的单词分组到一起，并默认按照字母进行排序。·Reduce阶段，将相同的单词进行累加。·输出结果。

### 9.1.1 什么是NoSQL

从技术层面上来说，HBase实际上是一个“数据存储”，而不是“数据库”，因为它缺乏关系型数据库的很多属性，如类型化列、辅助索引、触发器和高级查询语言等。一个关系型数据库虽然可以很好地被扩展，但仅限于某个点，也就是一个数据库服务器的大小，并且为了实现最佳性能，需要专用的硬件和存储设备。随着互联网的发展，传统的关系型数据库在应付超大规模和高并发的系统上已经显得“力不从心”，非关系型数据库就是在这样的背景下产生的。

### 9.1.2 NoSQL数据库的分类

NoSQL数据库共分为4类，分别是键值（Key-Value）存储数据库、列存储数据库、文档型数据库和图形（Graph）数据库，具体介绍如下。

Key-Value模型的优势在于简单且容易部署，可以将程序中的数据直接映射到数据库中，使程序中的数据和键值存储数据库中的数据存储方式很相近，比如Redis。

列存储数据库与传统的关系型数据库不同，关系型数据库按照行进行存储，而列数据库是每一列单独存放，仅仅查询所需要的列，查询速度大幅提高。在HBase中，这些列是由列家族来安排的。

文档型数据库和键值存储类似。该类型的数据模型是将内容按照某些特定的格式进行存储，如JSON格式和MongoDB就属于文档型数据库。

由于NoSQL数据库并没有标准的查询语言（SQL），所以在进行数据库查询时需要制定数据模型，如Neo4j。

### 10.2 Flume的特点

Channel中的File Channel具有持久性，事件写入File Channel后，即使Agent重新启动，事件也不会丢失。Flume中还提供了一种Memory Channel的方式，但它不具有持久存储的能力，数据完整性不能得到保证；与FileChannel相比，Memory Channel的优点是具有较高的吞吐量。

### 12.1 什么是Kafka

Kafka是Apache开发的一个开源流处理平台，它是一个可持久化的分布式的消息队列，最初由LinkedIn公司开发，是一个分布式、分区的、多副本的、多订阅者，基于ZooKeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于Web/Nginx日志、访问日志和消息服务等。

·Kafka是一个通用的系统，它可以有多个生产者和多个消费者共享多个Topic。

### 12.2 Kafka的架构和主要组件

Kafka的组件主要有：Producer（消息生产者）、Consumer（消息消费者）、Broker（Kafka集群的Server，负责处理消息读、写请求，存储消息）、Topic（消息队列/分类）、Partition、Offset和Segment。

### 12.2.3 其他组件——Broker、Partition、Offset、Segment

·Broker：Kafka节点，一个Broker就是一个Kafka节点，多个Broker组合在一起可以构成一个Kafka集群。·Partition：每个Partition是一个有序的队列，它是Topic物理上的分组，一个Topic可以分成多个Partition。

### 第13章 开源的内存数据库——Redis

为了提升速度，可以从内存中取数据，通过这种方式来提升查询效率。Redis就是在这样的背景下应运而生的。

### 13.1 Redis简介

Redis是内存数据库，它作为热门的NoSQL数据库之一被很多互联网公司所使用。它是一个key-value存储系统，类似于Java中的Map；同时Redis还可以通过实现数据的持久化来防止数据丢失；Redis可以周期性地将更新的数据写入磁盘中。

### 13.1.2 Redis的特点

·数据读取性能高，速度快，主要适合存储一些读取频繁、变化较小的数据。·支持丰富的数据类型。

·原子性：Redis的操作都是原子性的，支持事务。所谓原子性就是指一系列对数据的操作要么都成功，要么都失败。原子性的特点使我们不用去考虑并发的问题。

·其他特性：Redis还有一个特点就是可以设置key的过期时间，一旦到了过期时间，Redis会自动删除缓存信息。另外，Redis也可以将内存中的数据以异步的方式写入硬盘中，从而可以避免内存数据丢失的问题。

### 13.4 Redis的数据类型

在Redis中主要支持5种类型：String、List、Hash、Set及Sorted Set，其中Sorted Set是有序集合

### 第14章 Ambari和CDH

在开发大数据项目时需要有大数据环境。在企业中安装与配置Hadoop时，有的是基于原生Hadoop完成搭建，有的是基于工具来完成。目前使用的工具主要有两个，一个是Ambari，另一个是CDH

### 14.1 Ambari的安装与集群管理

Ambari是Apache的顶级项目，它是一个基于Web页面的工具，可以用于安装、配置、管理和监视Hadoop集群，同时支持HDFS、MapReduce、Hive、HBase、ZooKeeper和Oozie等。Ambari还提供了仪表盘，通过仪表盘可以查看集群的运行状况，而且提供了友好的用户界面，便于对运行性能进行诊断。

### 14.2 CDH的安装与集群管理

Ambari是开源免费的。目前业界还有一个用得比较多的工具是CDH（ClouderaDistribution Hadoop），CDH是把Apache的Hadoop开源项目进行了商业化，集成了很多补丁，可以减少大幅的安装工作，可以直接用于生产环境。

### 14.2.1 什么是CDH和Cloudera Manager介绍

Cloudera Manager的作用是为了协助管理CDH集群，Cloudera Manager提供了统一的UI界面，这样便于系统管理者快速地自动配置和部署CDH及相关组件，其中包括Hadoop整个生态圈的组件，例如Hadoop、Hive、HBase、Sqoop和ZooKeeper等。

### 14.2.2 Cloudera Manager与Ambari对比的优势

·版本更新速度快，划分清晰。·易用、稳定。·商用版有着更好的技术服务。·支持多种安装方式。·市场占有率高。

### 第15章 快速且通用的集群计算系统——Spark

Spark是一个统一的、用于大数据分析处理的、快速且通用的集群计算系统。它开创了不以MapReduce为执行引擎的数据处理框架，提供了Scala、Java、Python和R这4种语言的高级API，以及支持常规执行图的优化引擎。

### 16.3 数据收集

原始数据需要通过数据采集来完成，而数据采集通常分为两种方式，第一种方式是从手机App、网站和其他设备上通过日志收集工具进行收集，这里的日志收集工具可以使用Flume；第二种方式是从现有的系统中进行收集，如MySQL/Oracle导入，导入的工具可以使用Sqoop。

### 16.4 数据预处理

将收集的数据上传到了HDFS上，下面就需要完成数据的清洗工作了。所谓数据清洗，主要是对各种“脏”数据（不符合要求）进行相应处理，一是为了解决数据的质量问题，二是使数据更加便于做挖掘与分析。不同的目的，清洗方式和规则也不一样，包括但不局限于“数据完整性”“数据唯一性”“数据合法性”“数据一致性”等。

### 16.8 小结

完成了从数据采集、数据清洗与转化，到数据分析。再到最终的数据展现，使读者对大数据的项目开发有个整体认知。

### 第18章 基于个性化的视频推荐系统实战

用户的喜好对于商家来说已经成为了一项重要信息，用户倾向的推荐也越来越重要。

### 18.6 小结

本章通过对已知的用户视频观看信息，构建了“视频-视频相似度”和“用户-视频相似度”模型表，并利用协同过滤推荐算法实现了用户的视频推荐，推荐更贴合消费者喜好的视频，这对视频平台提高播放量有重要作用。