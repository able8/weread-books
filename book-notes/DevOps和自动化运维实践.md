## DevOps和自动化运维实践
> 余洪春

### 推荐序一

DevOps就是为了解决开发团队与运维团队之间存在已久的冲突及矛盾：开发团队责怪运维团队的机器出了问题，运维团队则把问题归咎于开发团队的代码上。

本书以实现DevOps为主线，涵盖了实现过程中的核心要素：Shell应用、Python应用、基础环境搭建、自动化运维工具、自动化部署管理等。

### 前言

现阶段我的职务是高级运维开发工程师（DevOps）、系统架构师，主要工作是负责公司的CDN业务系统的运维自动化及公司APP产品的CI/CD工作及自动化部署工作。CDN系统相对于其他领域而言，海量机器的自动化运维工作是一件比较复杂的事情，关于这项工作，我们可以通过Python自动化配置管理管理工具，例如Ansible和SaltStack来进行二次开发，结合公司的CMDB系统，提供稳定的后端API，方便前端人员或资产人员进行调用，这样大家都可以利用界面来完成自动化运维工作。

该项目现在全部部署在云平台（国内云平台）并且Docker容器化了，从前端到后端包括大数据接口，全部采用容器化的项目方式部署上线，整个自动化流程跟传统的自动化方式大相径庭。尤其是现在公司正在使用的Kubernetes，整个架构设计非常复杂，学习成本也是非常高的，但带来的容器的自动化管理也是非常便利的。目前，无论是国外的AWS、Google还是国内的阿里云和腾讯云等主流公有云均提供Kubernetes的容器服务，可以说Kubernetes在当前容器行业是热门的，而Docker技术正是Kubernetes的基石，建议大家尽快熟练Docker的使用方法。

### 撰写本书的目的

云计算和容器技术是当前的流行技术和发展趋势，云计算和容器技术的流行对于传统的运维知识体系其实也是一种冲击，传统运维工程师的工作性质也在不断地发生变化，要掌握很多新的技能和知识。

例如笔者目前正在从事的CDN领域，由于机器数量众多、网络环境错综复杂，也需要由DevOps人员来设计工具，提供后端的自动化运维API，结合公司的CMDB资产管理系统，提供自动化运维功能，简化运维的操作流程及步骤，提高工作效率。

### 第1章 DevOps与自动化运维的意义

DevOps具象成了建立一套有效率的开发运维工具，通过这个工具提升个体与团队协作的效率。为了建立和使用这些工具，运维人员必须具备一系列的技能，比如会使用Python、Go语言进行开发，会使用Puppet、Ansible、Saltstack等一系列工具，并能对这些工具进行二次开发

### 1.1 DevOps在企业中存在的意义

DevOps如今的兴起与最近两年云计算的快速普及有很大的关系：在云计算平台上，各种资源，从服务器到网络、负载均衡都是有API可以创建和操作的，这就意味着所有的资源都是可以用“软件定义”的，这就为各种自动化运维工具提供了一个非常好的基础环境。

从测试环境发布到线上环境的持续发布能力，这种能力称为持续集成（CI）

DevOps是一个完整的、面向IT运维的工作流，其以IT自动化以及持续集成（CI）、持续部署（CD）为基础，用于优化程序开发、测试、系统运维等所有环节。

DevOps的一个巨大的好处就是可以高效地交付，

### 1.2 为什么企业需要自动化运维

自动化运维把周期性、重复性、规律性的工作交给自动化平台（或产品）去处理，通过标准化、自动化、架构化、过程优化来降低运维成本、提高运维效率。

### 1.3 Web编程相关体系知识点

很多时候，我们从事DevOps（包括自动化运维）的工作就是将运维工作Web化、API化，这往往会牵涉大量后端开发知识，

则前端与后端分别处理如下内容。
前端：负责View和Controller层。
后端：只负责Model层，进行业务处理和数据处理等。

前后端分离之后，两端的开发人员都可以轻松不少，由于技术和业务都变得更为专注，因此开发的效率也得到了提高。

5）客户端每次向服务器端请求资源的时候都需要带着服务器端签发的Token。
6）服务器端收到请求，然后去验证客户端请求中所携带的Token，如果验证成功，就向客户端返回请求的数据。

支持跨域访问： Cookie是不允许跨域访问的，这一点对Token机制来说是不存在的，Token机制支持跨域访问的前提是用户认证信息通过HTTP头传输。

无状态（也称服务器端可扩展行）:Token机制在服务器端不需要存储Session信息，因为Token自身包含了所有登录用户的信息，因此只需要在客户端的Cookie或本地介质中存储状态信息即可。

Rab bitMQ的缺点具体如下。
1）由于牺牲了部分性能来换取稳定性，比如消息的持久化功能，使得RabbitMQ在大吞吐量性能方面不及Kafka和ZeroMQ。
2）由于支持多种协议，因此RabbitMQ非常重量级，比较适合于企业级开发。

Linux集群，即负载均衡高可用

Session在网络应用中常称为“会话”，借助它可以提供服务器端与客户端系统之间必要的交互。因为HTTP协议本身是无状态的，所以经常需要通过Session来解决服务器端和浏览端的保持状态的解决方案。Session是由应用服务器维持的一个服务器端的存储空间，用户在连接服务器时，会由服务器生成一个唯一的SessionID，该SessionID可作为标识符用于存取服务器端的Session存储空间。
SessionID这一数据是保存到客户端的，用Cookie进行保存，用户提交页面时，会将这一SessionID提交到服务器端，来存取Session数据。服务器端也可以通过URL重写的方式来传递SessionID的值，因此它不是完全依赖于Cookie的。如果客户端Cookie禁用，则服务器端可以通过重写URL的方式来自动保存Session的值，并且这个过程对程序员是透明的。

### 1.4 从事DevOps工作应该掌握的语言

1）部署简单。Go语言编译生成的是一个静态可执行文件，除了glibc之外再没有其他的外部依赖。这也使得部署变得异常方便：目标机器上只需要一个基础的系统和必要的管理、监控工具，完全不需要操心应用所需的各种包、库的依赖关系，这就大大减轻了维护的负担。

2）并发性好，天生支持高并发。G

下面再来看看Go语言适用的场景，具体如下。
1）服务器编程，如果大家以前习惯使用C或者C++来进行服务器编程，那么用Go来做也是很合适的，例如日志处理系统、数据打包、虚拟机处理、文件系统等。
2）分布式存储、数据库代理器等。
3）Key-Value存储，例如工作中常见的etcd。
4）网络编程，目前这一块应用得最广，包括Web应用、API应用、下载应用等。

### 1.5 从事DevOps工作应该掌握的工具

Jenkins在国内的使用率为70%!左(MISSING)右。

### 1.6 了解网站系统架构设计和高并发场景

网站设计得好还是不好，我们可以参考吞吐量、每秒查询率（QPS）、响应时间（Response Time）、并发用户数，PV等作为辅助指标，但它们并不能真实地反映网站的性能。

网站架构一般分成网页缓存层、负载均衡层、Web服务器层、数据缓存层及数据库层，其实一般还会多加一层，即文件服务器层

Nginx已经具备Squid所拥有的Web缓存加速功能。此外，Nginx对多核CPU的利用也胜过了Squid，现在越来越多的架构师都喜欢将Nginx同时作为“负载均衡服务器”与“Web缓存服务器”来使用，

必须合理地设计MySQL数据库的架构，事实上，在生产环境下，一主多从、读写分离是比较靠谱的设计方案，对于MySQL的负载均衡，这里推荐大家使用LVS/DR，这是因为当从机MySQL节点机器超过十台时，HAProxy的性能便会不如LVS/DR。

### 1.8 Linux服务器的安全防护

访问该服务器会一致性地返回302，使用户浏览器跳转到预处理好的带广告的网页，在该网页中再通过iframe打开用户原来访问的地址。

### 2.1 Shell编程基础

特殊变量“$*”和“$@”表示所有的位置参数。
特殊变量“$#”表示位置参数的总数。

read -p "Enter your name:" yhc￼

### 2.5 Shell应用于DevOps开发中应掌握的系统知识点

wait命令有一个很重要的用途就是在Shell的并发编程中，可以在Shell脚本中启动多个后台进程（使用“&”），然后调用wait命令，等待所有后台进程都运行完毕，Shell脚本再继续向下执行。我们继续用time命令进行统

### 2.6 生产环境下的Shell脚本

#配置文件的ulimit值￼
        ulimit -SHn 65535￼
        echo "ulimit -SHn 65535" >> /etc/rc.local￼
        cat>> /etc/security/limits.conf << EOF￼
        ＊                         soft      nofile                65535￼
        ＊                         hard      nofile                65535￼

基础系统内核优化￼
        cat>> /etc/sysctl.conf << EOF￼
        fs.file-max=419430￼
        net.ipv4.tcp_syncookies = 1￼
        net.ipv4.tcp_syn_retries = 1￼
        net.ipv4.tcp_tw_recycle = 1￼
        net.ipv4.tcp_tw_reuse = 1￼
        net.ipv4.tcp_fin_timeout = 1￼
        net.ipv4.tcp_keepalive_time = 1200￼
        net.ipv4.ip_local_port_range = 102465535￼
        net.ipv4.tcp_max_syn_backlog = 16384￼
        net.ipv4.tcp_max_tw_buckets = 36000￼
        net.ipv4.route.gc_timeout = 100￼
        net.ipv4.tcp_syn_retries = 1￼
        net.ipv4.tcp_synack_retries = 1￼
        net.core.somaxconn = 16384￼
        net.core.netdev_max_backlog = 16384￼
        net.ipv4.tcp_max_orphans = 16384￼
        EOF￼
        /sbin/sysctl -p￼

#关闭iptables￼
        service iptables stop￼
        chkconfig iptables off￼

### 3.1 Python语言的应用领域

私有云平台中大名鼎鼎、如日中天的OpenStack，就是以Python编程语言编写的。

### 3.3 Python的版本说明

Python 3源码文件默认使用UTF-8编码，而Python 2.x默认使用的则是Unicode编码。

### 3.5 Python基础知识进阶

1）使用re.compile()对正则表达式进行预编译，实现更加高效的匹配。
2）编译后再使用findall()函数根据正则表达式从源字符串中将匹配的结果全部找出。代码如下所示：

❑ re.sub()函数
很多时候，我们需要根据正则表达式来实现替换某些字符串的功能，此时就可以使用re.sub()函数来实现

json.dumps是将Python对象编码成JSON字符串，我们先列举一个简单的例子说明下，代码如下所示

内部函数可以看作是一个闭包（Closer）。闭包是一个可以由另一个函数动态生成的函数，并且其可以改变和存储函数之外创建的变量的值。

Python使用lambda来创建匿名函数

要创建一个generator（生成器），有很多种方法。第一种方法很简单，只要把一个列表生成式的“[]”改成“()”，就创建了一个generator，

### 3.6 Python经常用到的第三方类库

sh:sh类库使得我们可以用Python函数的语法去调用Linux Shell命令，相比较于subprocess标准库而言，sh确实方便多了。

### 3.7 利用Flask设计后端Restful API

Flask是轻量级、易于采用、文档化和流行的开发RESTful API的非常好的选择，也是笔者在工作中最常用的Flask Web框架之一。从根本上说，Flask是建立在可扩展性和简单性的基础之上的。Flask应用程序以轻量级而闻名，主要是与Django对比。Flask开发者称之为微框架，其中“微”（如这里所述）意味着目标是保持核心简单但可扩展

在DevOps中使用RESTful API的原因如下：
❑ 返回的不是HTML，而是机器能直接解析的数据。
随着Ajax的流行，API返回数据，而不是HTML页面，数据交互量减少，用户体验会更好。前后台分离，后台更多地进行数据处理，前台对数据进行渲染。
❑ 直接使用API可以进行CRUD，增删改查，结构清晰。
一个标准的API有4个接口：GET、PUT、POST、DELETE，对应我们的请求类型，就是Web获取页面、上传表单（或文件）、更新资源或删除资源。

相对而言，Tocken认证比Cookie认证更为安全，毕竟Cookie认证是我们爬网站时使用最多的伪造渠道。
❑ 越来越多的开放平台，开始使用API接口。

这样，一个简单的RESTful API就完成了，直接GET请求首页将返回相应的数据，

### 3.8 工作中的Python脚本分享

将所有任务加入队列￼
              for i in range(len(imglist)):￼
                queue.put(imglist[i])￼

### 4.1 Vagrant简单介绍

Vagrant就是为了方便地实现虚拟化环境而设计的，使用Ruby开发，基于VirtualBox等虚拟机管理软件的接口，提供一个可配置的、轻量级的便携式虚拟开发环境。使用Vagrant可以很方便地建立起一个虚拟环境，而且还可以模拟多台虚拟机，这样我们平时还可以在开发机中模拟分布式系统。

### 4.5 使用Vagrant搭建分布式环境

Vagrant支持单机模拟多台机器，而且支持一个配置文件Vagrantfile就可以运行分布式系统了

### 第5章 自动化部署管理工具Ansible

Ansible是一款轻量级的服务器集中管理软件。Ansible默认采用SSH的方式管理客户端，部署简单，只需要在跳板机或主控端部署Ansible环境即可，被控端无须进行任何操作。

相比较于其他自动化运维工具，Ansible的优势也有很多，具体如下。
❑ 轻量级，无须在客户端安装Agent，更新时只需要在操作机上进行一次更新即可。
❑ 批量任务执行可以写成脚本，而且不用分发到远程就可以执行。
❑ 使用Python编写，维护简单，二次开发更方便。
❑ 支持非root用户管理操作，支持sudo。
❑ 支持云计算、大数据平台（如AWS、OpenStack、CloudStack等）。

Ansible易于使用：这一点从下面的两个例子得以体现。一是，Ansible的playbook使用的是人类可读的YAML代码编写，简化了自动化流程的编写和维护；二是，Ansible使用标准的SSH连接来执行自动化流程，不需要代理，更容易融入已有的企业IT环境。

### 5.1 YAML介绍

❑ 列表（list）：一组按次序排列的值。

YAML中的多行字符串可以使用“|”保留换行符，也可以使用“>”折叠换行

首先是列表（list），在该语法中，列表中的所有成员都开始于相同的缩进级别，并且使用一个“-”作为开头（一个横杠和一个空格）

YAML中提供了多种常量结构，具体包括整数、浮点数、字符串、NULL、日期、布尔、时间等

- TRUE  #true, True都可以￼
- FALSE  #false, False都可以￼

        datetime:￼
-2018-02-17T15:02:31+08:00     #时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用“+”代表时区

### 5.4 Ansible常用模块介绍

facts组件是Ansible用来采集客户端机器设备信息的一个重要功能，setup模块可用于获取Ansible客户端机器的所有facts信息

❑ force：如果目标主机包含该文件，但内容不同，则设置为yes后会强制覆盖，设置为no时，只有当目标主机的目标位置不存在该文件时才复制；默认为yes。
❑ backup：在覆盖之前备份源文件，备份文件包含时间。backup包含两个选项，即yes和no。
命令显示结果如下所示：

script模块用于在远程被控端主机执行本地Ansible机器中的Shell脚本文件，相当于“scp+shell”的组合命令，比如，要执行本地机器的/root/print_hello.sh

get_url模块可以实现在远程主机上下载url到本地，这个模块在平时的工作中应该用得比较多，

### 5.5 playbook介绍

（3）Handlers
若被控端主机的配置文件发生了变化，则通知处理程序Handlers触发后续的动作，比如重启Apache服务。Handlers中定义的处理程序在没有通知触发时是不会执行的，触发是通过Handlers定义的name标签来识别的，请让下面的notify中的“restart apache”与handlers中的“name:restart apache”的内容保持一致。

### 5.8 Jinja2过滤器

Jinja2提供了一个有用的default过滤器，相比于未定义变量时直接fail，使用default过滤器是一个更好的方法：

### 5.9 Ansible速度优化

Ansible默认是同步阻塞模式，它会等待所有的机器都执行完毕之后才会在前台返回。
Ansible默认只会创建5个进程并发执行任务，所以一次任务只能同时控制5台机器执行。如果有大量的机器需要控制，例如20台，那么Ansible执行一个任务时会先在其中5台上执行，执行成功后再执行下一批5台，直到所有机器全部执行完毕。使用“-f”选项可以指定进程数，我们的线上环境设置的值为20（这个值配置过大并不会对Ansible的实际执行效率有很大的提升，还是需要结合实际应用场景来进行设置）。

还支持异步模式。
总体来说，大概有如下的一些场景需要使用到Ansible的异步执行特性。
❑ 当我们有一个task需要运行很长的时间，而且这个task很可能会达到timeout时。
❑ 当我们有一个任务需要在大量的机器上面运行时。
❑ 当我们有一个任务不需要等待它完成时。

Ansible也考虑到了这种情况，官方文档介绍了上述问题的解决方法，就是让下发的任务执行的连接变为异步：任务下发之后，长连接不再保持，而是每隔一段时间轮询一次结果，直到任务结束为止。

async参数值代表了这个任务执行时间的上限值。即任务执行所用的时间如果超出了这个时间，

poll参数值代表了任务异步执行时轮询的时间间隔。

可以指定任务检查的时间间隔，默认是10秒。除非指定任务检查的时间间隔为0，否则会等待所有任务都完成后，Ansible端才会释放占用的Shell。如果指定的时间间隔为0，则Ansible会立即返回（至少得连接上目标主机，任务发布成功之后立即返回），并且不会检查它的任务进度。

“-B 30”表示启用异步，超时时间为30; “-P 0”表示将轮询时间设置为0，即不检查任务进度，立即返回结果。

这个协议就是我们通常所说的“三次握手”，普通的SSH开销并不大。但当我们用Ansible运行playbook的时候，它会建立大量SSH连接来执行复制文件、运行命令这些类似的操作。Ansible每次都会重新创建到主机的SSH连接，这当然需要付出三次握手的开销，大量的SSH连接也意味着大量的开销。

OpenSSH支持一个优化，称为SSH Multiplexing（简称为多路复用），也称作ControlPersist。当我们使用SSH Multiplexing的时候，多个连接到相同的被控制主机的SSH会话将会共享相同的TCP连接，这样就只有在第一次连接的时候需要进行TCP三次握手了。

启用SSH Multiplexing后运行过程具体如下：
1）当我们用Ansible主控端机器尝试SSH被控端机器时，OpenSSH创建一个主连接。
2）OpenSSH创建一个Unix域套接字，通过Ansible机器与被控端机器相关联。
3）当再次尝试连接被控制端机器时，OpenSSH将使用Unix域套接字与远程主机进行通信，而不会创建新的TCP连接。

 ControlMaster auto￼
        ControlPath    /tmp/master-%!r(MISSING)@%!h(MISSING):%!p(MISSING)￼
        ControlPersist 10m



        time ssh -p 12321 61.130.2.25 /bin/true

ssh_args = -o ControlMaster=auto -o ControlPersist=10M￼
        control_path = %!((MISSING)directory)s/%h-%r

pipelining也是OpenSSH的特性之一，

1）Ansible基于调用的模块生成一个Python临时脚本。

下面再来编辑一下Ansible配置文件，在[ssh_connection]下添加如下内容：
￼
        pipelining = True

目前Ansible支持如下几种方式来缓存facts，具体如下。
❑ 本地json文件
❑ redis
❑ memcached


        gathering = smart￼
        fact_caching = redis￼
        fact_caching_timeout = 86400￼
        fact_caching_connection = 127.0.0.1:6379


        time ansible-playbook mytest.yml -f 3
时间上应该是有明显的加速的，特别是在机器数量比较多的情况下。

### 5.10 利用Ansible API提供自动化运维后端

Ansible作为自动化运维的底层实现，功能很强大，但是需要通过命令或playbook的YAML文件来实现，相对于运维人员和非运维人员而言，学习成本过大。所以这里考虑通过Flask Web框架来实现其二次封装，提供HTTP接口来实现远程调用。但是，我们在请求Ansible API的时候，Ansible默认其本身是阻塞的，用户那边将一直处于等待状态，这样大家的用户体验也不好，所以这里会用redis-queue来实现其非阻塞功能，即实现任务的异步化Flask + Ansible的任务流程逻辑处理图如图5-2所示。

### 6.1 Salt的相关知识点介绍

❑ 主控端（Master）和被控端（Minion）基于证书认证，安全可靠。
❑ 配置简单、功能强大，可扩展性强。
❑ 支持API及自定义模块，可以通过Python轻松扩展。
❑ 速度优于其他自动化配置管理工具。
❑ 支持现如今所有流行的云平台及Docker和openstack。

我们曾做过Salt与Ansible的对比，在连通性方面，Salt的速度要比Ansible快50倍左右。众所周知，CDN的网络环境是最复杂的，除了电信、联通（包含铁通）、移动的线路之外，我们还得考虑广电网和教育网等网络，虽然跳板机是部署在网络质量最好的三线机房里面，但考虑到速度、安全及执行效率等方面，我们在这里选择了Salt来作为此项目的自动化配置管理工具。

### 第7章 Docker和Jenkins在DevOps中的应用

所以Docker是非常适合DevOps的。而Jenkins是一个开源的、提供友好操作界面的持续集成（CI）工具，起源于Hudson（Hudson是商用的），主要用于持续、自动地构建或测试软件项目、监控外部任务的运行（这个比较抽象，暂且写上，不做解释）。

### 7.2 Docker的三大核心概念

Docker的三大核心概念列举如下：
❑ 镜像（Image）
❑ 容器（Container）
❑ 仓库（Repository）

Docker镜像类似于虚拟机镜像，可以将其理解为一个面向Docker引擎的只读模板，包含了文件系统。

容器类似于一个轻量级的沙箱，Docker利用容器来运行和隔离应用。容器是从镜像创建的应用运行实例，可以对其进行启动、开始、停止、删除操作，而这些容器都是相互隔离、互不可见的。可以把容器看作一个简易版的Linux系统环境

### 7.3 Docker的基本架构

Docker Host默认监听本地的uninx://var/run/docker.sock套接字，只允许本地的root用户访问，如果是远程机器要访问本地的Docker服务呢？我们可以通过-H选项来修改监听的方式，例如，让Docker Host监听本地的TCP连接端口12321，具体操作如下所示：
编辑/lib/systemd/system/docker.service文件，注释掉原先的ExecStart选项，更改为如下形式：
￼
        ExecStart=/usr/bin/dockerd -H unix://var/run/docker.sock -H tcp://0.0.0.0:12321
然后重启Docker服务，命令如下所示：
￼
        systemctl daemon-reload￼
        systemctl restart docker.service

docker -H tcp://10.0.0.43:12321 images

由于开了监听端口，任何人都可以通过远程连接到本地的Docker Daemon服务器进行操作，所以操作此步骤时需要谨慎，这里还是推荐采用本地Socket的方式来运行Docker。

### 7.6 利用Docker-Compose编排和管理多容器

以下命令用于查看Nginx的实时日志：
￼
        docker-compose logs -f nginx

以下命令用于以json的形式输出Nginx的docker日志：
￼
        docker-compose events --json nginx
以下命令用于暂停Nginx容器：
￼
        docker-compose pause nginx

### 7.7 利用Docker搭建Jenkins Master/Slave分布式环境

在Jenkins Master/Slave分布式架构中，Master机器主要用来分发构建任务给Slave，实际的执行和操作均在Slave机器中进行。Master监控Slave的状态，并收集展示构建的结果。但是在实际情况中，Master同样可以执行构建任务。

### 第8章 自动化运维的后续思考

自动化是IT运维工作的升华，自动化运维不单纯是一个维护过程，更是一个管理的提升过程，是IT运维的较高层次。


### 8.1 自动化运维系统中应该实现的系统

下面三个系统在自动化运维体系中是不可缺少的：
❑ CMDB管理系统。
❑ 持续集成系统。
❑ 运维调度管理系统。

即机器主机名、IP名、业务角色、隶属平台、机器类型、归属线路

2．持续集成系统
这里选择的持续集成系统是开源的Jenkins，但我们也在Jenkins的基础上做了大量的改造工作，例如我们采用的是Jenkins的Master/Slave分布式架构，而且Slave节点全部是由Docker来实现，即将Jenkins置于Docker容器内运行。

2）Jenkins系统通过Web Hook插件（此插件可选，不选的话需要手动构建）检测到了代码有变化，执行自动化构建过程，通过Dockerfile文件打包镜像。

4）可以及时将构建成功与否的结果推送给相关人员（推荐安装钉钉通知器插件，并使钉钉通知器里带有Jenkins的部署项目和版本号），比如测试人员，以安排测试。

8s的滚动升级可以使得服务近乎无缝地平滑升级，即在不停止对外服务的前提下完成应用的更新，目前我们在测试和开发环境上面都已部署了k8s，后续准备在生产环境下推广k8s。

3．运维调度管理系统
运维调度管理系统，有的公司也称之为“运营系统”，该系统是对复杂运维事务的封装，个人觉得运维调度管理系统是上述所有子平台中最有技术含量的，我们在运维过程中会接触到很多复杂的运维场景，比如容灾切换、服务迁移、熔断机制、扩容或缩容等，这些都不是简单地通过单一运维动作就能够完成的，需要综合考虑很多因素（最直接有效的监控指标就是业务参数和大数据日志分析），这也是我们需要花精力思考和总结的地方。

### 8.2 自动化运维经历的阶段

自动化运维的第二阶段是Web化，相信每个公司都会根据自己的实际情况设有自己的管理平台，通过这个平台我们可以控制登录人员的权限，规范运维流程、运维的标准化流程，还有case的收集及整理等，通过这些我们能解决运维中的痛点，并且通过将运维Web化，很多运维操作不仅仅运维人员可以执行，其他人员通过平台的Web操作也能完成运维人员的标准化流程操作。

自动化运维的第四阶段，即智能化运维，这是最高级别的运维自动化。一般来说，此时的平台或系统都已经有了机器学习的能力，能根据当前的业务级别来自动扩容或缩容、进行故障的自动修复等，但这些工作也是非常复杂的，需要大量收集业务运营指标，然后通过机器学习的手段来自动地进行智能调整，这也需要技术团队做大量的工作，这也是目前自动化运维努力的目标。

### 8.4 因地制宜地选择自动化运维方案

现在我们的APP项目的架构方案主要是容器微服务化，Docker发布和k8s都在项目中使用，尤其是Docker，前端和后端程序均采用Docker化的方式来进行部署和发布。这对于运维人员的运维方式来说也是一个巨大的改变，而且Docker容器的自动化部署较依赖于k8s，随着k8s的深入使用，我们发现k8s在很多方面占据了巨大的优势，例如容器编排、水平自动扩展、滚动升级、负载均衡还有资源监控，这也坚定了我们在生产环境下持续部署和使用k8s的决心。

打造自动化运维平台，最难的不是如何开发，而是积累场景，长期积累各种业务场景才能打造出最合适的自动化运维平台。自动化运维不是终点，积累场景和大数据才是关键，所以自动化运维的每一步中都应该做好对数据和场景的积累。等到将来场景模型完全建立起来，我们才能实现最终的自动化运维目标。

### A.1 GitLab的优势所在

1）Git的速度是明显快于SVN的。
2）Git天生就是分布式的。它包含本地版本库的概念，是可以离线提交代码的（这一点是相对于SVN集中式管理的优势）。
3）强大的分支管理功能，非常方便多人协同开发。

### A.3 GitLab的基础操作命令

简要查看历史，将每次的修改显示在一行，命令如下所示：
￼
        git log -pretty=oneline
把当前的版本回退到上1个版本，命令如下所示：
￼
        git reset --hard HEAD^
把当前的版本回退到上2个版本，命令如下所示：

### A.4 GitLab的Git Flow操作流程

Git Flow就是为项目开发一个新功能需要的操作流程，具体如下。
1）创建新的功能分支。
2）逐渐实现功能，做成一个的新版本。
3）发起merge request。
4）大家一起来看看这些代码怎么样，即Code Review。
5）若大家感觉没问题了，将功能分支合并到master分支，并删除功能分支。

### 附录B 用Gunicorn部署高性能Python WSGI服务器

Python项目中性能较好的软件就是Gunicorn, Gunicorn也称为“绿色独角兽”，是一个使用广泛的、高性能的Python WSGI UNIX HTTP服务器，移植自Ruby的独角兽（Unicorn）项目，使用pre-fork worker模式，具有使用非常简单，轻量级的资源消耗，以及高性能等特点。

Gunicorn服务器作为WSGI APP的容器，能够与各种Web框架兼容（Flask、Django及其他Web框架等），得益于gevent等技术，使用Gunicorn能够在基本不改变WSGI APP代码的前提下，大幅度提高WSGI APP的性能。

限制HTTP请求中请求头的大小，默认情况下这个值为8190。该值是一个整数或者0，当该值为0时，表示将不对请求头大小进行限制。

### 附录C Supervisor在DevOps工作中的应用

Supervisor，简单来说就是Python编写的一个多进程管理工具。虽然在Shell下面我们可以用nohup命令的方式将程序放在后台执行，一个或几个可能还比较方便，但如果有很多重要的进程需要管理的话，那就不方便了。

### 附录D 分布式队列管理Cerely简介

Celery是一个基于Python开发的分布式异步消息任务队列，其可以有助于轻松地实现任务的异步处理。如果在我们的业务场景中需要用到异步任务，则可以考虑使用Celery

比如说，我们想对200台机器执行一条批量命令，可能会花费很长时间，但不想让程序等待返回结果，这个时候我们就可以考虑使用Cerely; Cerely会向我们返回一个任务ID，过一段时间之后我们只需要拿着这个任务ID就可以拿到任务执行结果，在任务执行的过程中，大家可以继续做其他的事情。

 tasks：即我们想在队列中进行的任务，一般由用户、触发器或其他操作将任务入队，然后交由works进行处理。